= image:img/vassblue.png[Vass logo] &nbsp;&nbsp;&nbsp; Proyecto _cicd-librerias_
Faustino Nebrera <faustino.nebrera@vass.es>
1.0.2, 19/10/2022
:toc:
:toc-title: Tabla de Contenido
:toclevels: 4
:sectnumlevels: 4
:icons: font

== Resumen

Este proyecto representa un ejemplo completamente operacional de una cadena CI/CD construida con la idea de simplificar el stack
DevOps, la instalación de productos requeridos y, sobre todo, la preparación de pipelines y jobs para los circuitos más
habituales. No se ha pretendido hacer comparativas de productos y, menos aún, establecer una guía estricta de
cómo hacer las cosas, puesto que cada Compañía y/o Departamento de TI tiene su propia normativa. Por esta razón, las librerías son
muy flexibles, y pueden adaptarse con muy poco trabajo a diferentes normativas y procedimientos. 

Esta versión 1.0.2 es específica para proyectos maven/java desplegados como stacks Docker. El provisioning es
bastante genérico y se basa en Terraform. Para deploy, se ha optado por emplear bash y ssh, pensando en entornos no demasiado complejos.

En versiones posteriores está previsto replicar una parte de las librerías para incluir proyectos basados en phyton, node.js, .Net.core, etc. También está previsto incorporar la posibilidad de emplear algún producto sofisticado de deploy, tipo Ansible u Octopus. Por último, se trabajará en el provisionado y despliegue de proyectos basados en microservicios (kubernetes, swarm, etc.).
 
== Versiones

[cols=".<1,.<1,.<1,.<6", options="header"]
|===
|Vers
|Por
|Fecha
|Notas

|1.0.0
|FNG
|22/08/2022
|Primera versión CI/CD para maven/java

|1.0.1
|FNG
|25/09/2022
|Se agrega provisioning con Terraform y se generaliza el deploy usando bash y ssh

|1.0.2
|FNG
|19/10/2022
|Se incorpora un mecanismo para manejar librerías de funciones, y se generalizan las etapas de provisioning y deploy

|===

:sectnums:
== Introducción

Los stacks CI/CD más habituales están compuestos de varios productos, especializados cada uno de ellos en un aspecto concreto
de la cadena o pipeline de la solución final. Es muy frecuente encontrar stacks que incluyen 6 o más
productos diferentes: Gitlab, Jenkins, Sonar, Nexus, Vault, Octopus, etc.

Es evidente que instalar (y sobre todo configurar) muchos productos heterogéneos no es un trabajo trivial. Algunos vendors
permiten simplificar esta tarea mediante soluciones previamente integradas (véase el caso de RedHat OpenShift, los servicios
CI/CD de Amazon Web Services o Azure, etc.) aunque, lógicamente, no se trata de simples black-boxes, puesto que cada organización
tiene sus propios requisitos de CI/CD. No es lo mismo un pequeño ISV que una gran Entidad Financiera, por lo que siempre es necesario
hacer "retoques" sobre las configuraciones por defecto, o incluso crearlas desde cero.

Por otra parte, los coordinadores de tareas tipo _Jenkins(TM)_ se configuran mediante un lenguaje de
programación que, aunque sencillo, requiere que los ingenieros de DevOps tengan ciertos conocimientos de
programación y estén familiarizados con el lenguaje en cuestión. Si, además (y es lo habitual) el código debe
mantenerse como read-only para los desarrolladores, y debe ser modular (empleando
librerías), la curva de aprendizaje suele ser costosa.

En este proyecto se ha intentado minimizar:

- El número de productos implicados.
- La complejidad de la definición de
flujos de tareas (pipelines).

Para ello se han empleado algunas de las capacidades CI/CD que Gitlab ofrece en sus últimas versiones, y se han definido unos pipelines de ejemplo que se han probado en un entorno real, con resultados bastante satisfactorios.

[TIP]
.*Importante*
--
Independientemente de cuál sea tu formación previa en CI/CD, la lectura de este documento puede serte útil para afianzar conceptos básicos y entender la filosofía de los pipelines  de CI/CD.
--

== Entorno de desarrollo

=== Hardware y software de base

Server Hyper-V::
* Intel Core i7-7567U.
* 32 GB Memoria
* 1 TB SSD
* Windows Server 2022 Standard
* Hyper-V

Server CI/CD::
* Máquina virtual en Hyper-V.
* 24 GB Memoria max.
* 4 procesadores virtuales.
* Ubuntu 20.04.1
* Docker 20.10.17 y docker-compose

Maquinas provisionadas::
* Maquina virtual en Hyper-V.
* 2 GB Memoria max.
* 1 procesadores virtuales.
* Alpine Linux 3.16.2
* Docker 20.10.17 y docker-compose.
* Herramientas de base: OpenSSH-server, bash, sudo, etc.

=== Productos para CI/CD

Todos los productos se han instalado en el server CI/CD como imágenes docker, y se lanzan mediante sendos docker-compose, para facilitar
el arranque/parada de un producto concreto sin afectar al resto. Todos los docker-compose referencian un network
común tipo bridge. Al compartir network, se facilita la comunicación entre containers, puesto que Docker actúa
como DNS interno. Salvo en el caso de Nginx, no se exponen puertos TCP/IP al exterior. El acceso externo se
canaliza a través de Nginx (port 443), que actúa como proxy inverso, discriminando el acceso en base al hostname de destino. Los
productos instalados son:

- Gitlab OMNIBUS 15.2.1-ce.0
- Gitlab-runner: latest
- Sonarqube 9.6.1-community
- PostgreSQL 14.4 (usado por Sonar y Selfweb)
- Nginx 1.21.6 (proxy inverso)
- Portainer ce:2.15.1 (monitorización Docker)

== Visión general de la solución

=== Proyecto de trabajo

Las librerías de pipelines y jobs se encuentran en el proyecto "cicd-librerias", y se describirán con mayor detalle más adelante. Tanto las librerias como la documentación están disponibles en un repositorio público (githb).

Como proyecto de trabajo, se ha escogido la aplicación Selfweb de Comunytek, y concretamente el server REST (selfwebspingboot). Se trata de una aplicación java que emplea el framework SpringBoot. Como gestor de proyectos se emplea maven. En la carpeta "ejemplos_cfg"
puede verse el pom.xml de dicho proyecto, así como otros ejemplos de archivos de configuración.

=== Flujo de desarrollo

Como normativa se ha escogido el modelo "Git Flow" simplificado. Si bien los pipelines pueden fácilmente adaptarse
a otros modelos, este es el preferido por muchas organizaciones, y el que se emplea en este momento en los
proyectos del Clan Comunytek. El modelo es el siguiente:

image::img/gitflow.png[Git Flow]

- Debe existir una rama "master" que además es la de defecto. En esta rama debe estar el código de la última versión
liberada para producción, o en curso de liberarse. La rama está protegida de modo que sólo los "Mantainers"
pueden hacer merge y push.
- Debe existir una rama "develop". En esta rama debe estar el código de la última versión
liberada para preproducción, UAT, Staging, o en curso de liberarse. La rama está protegida de modo que sólo los "Mantainers"
pueden hacer merge y push.
- El desarrollo se realiza sobre ramas auxiliares, asociadas a todo el trabajo de desarrollo previo al deploy en pre: a una "feature", a un desarrollador, etc. Los desarrolladores
trabajan en local sobre su rama y, de forma periódica, hacen "push" a efectos de backup, lo que, opcionalmente,
puede disparar un pipeline de CI/CD.
- A medida que finaliza el trabajo de desarrollo en las diferentes ramas,
se unifican mediante merge sobre una rama temporal (p.e. "desa-5.0.9-sprint-34") en la que se revisan posibles inconsistencias, se realizan eventuales pruebas de integración y EndToEnd, etc.
- Una vez completada la rama temporal de desarrollo, un "Mantainer" hará merge local sobre "develop", resolverá eventuales inconsistencias y hará
push de "develop", lo que disparará un pipeline CI/CD asociado a pre-producción.
- Cuando un SNAPSHOT sea autorizado para producción, un "Mantainer" hará merge local de 'develop' sobre 'master',
modificará la versión en el pom (eliminando la cadena "SNAPSHOT"), y hará push de master, lo que disparará un pipeline CI/CD asociado a producción. 
- Pueden existir ramas hotfix, pero no más de una simultáneamente. Como veremos más tarde, esta rama (de existir) tiene
un tratamiento especial.

=== Gitlab como entorno CI/CD

En sus últimas versiones, Gitlab incorpora un conjunto de características que lo hacen un buen
candidato para soportar el grueso de las cadenas CI/CD de manera integrada. A continuación vamos a comentar
algunos de los aspectos principales.

==== Repositorio de código fuente

Git/Gitlab representan el estándar de-facto para la gestión de código fuente. No vamos a entrar
a explicar Git, por ser sobradamente conocido. Sin embargo, hay algunas características menos conocidas
que conviene mencionar.

- Gitlab incluye un *Issue Manager* sencillo pero bastante completo, hasta el punto de que, en algunos casos, podría
emplearse como sustituto de _Jira_(TM).
- También incluye una *Wiki* con soporte de varios lenguajes de markup que, como en el caso anterior,
podría emplearse como sustituto de _Confluence_(TM), al menos en lo que se refiere a documentación de los proyectos.

==== Coordinador CI/CD

Gitlab incluye un coordinador de CI/CD relativamente poco conocido, dado que tradicionalmente sus capacidades han estado por
debajo de los productos más usuales, tales como _Jenkins_(TM) o _TeamCity_(TM). En sus últimas versiones, sin embargo, Gitlab se ha posicionado
como un serio competidor, fundamentalmente por las siguientes razones:

* Todo el "plumbing" de CI/CD está estrechamente integrado con el repositorio de código fuente, emplea la misma interfaz de usuario,
y simplifica la eventual integración de otros productos.

* Los _pipelines_ se definen mediante un lenguaje de markup sobradamente conocido (yaml), lo que evita tener que aprender un lenguaje
específico.

* Si se requieren acciones complejas, el entorno de "shell" está directamente integrado con los jobs. Es muy fácil, además,
crear librerías de funciones escritas en .sh, .bash, etc. y llamarlas directamente desde un job. En un entorno complejo,
los ingenieros DevOps pueden concentrarse en la creación de la base de los pipelines, dejando determinados detalles de implementación de cada job a desarrolladores especializados.

Más adelante se explica en mayor detalle el modo de trabajar con Gitlab CI/CD.

==== Verificación de Calidad del Código

En este apartado, Gitlab no dispone de una solución propia, sino que
integra el producto _CodeClimate(TM)_. Dado que el estándar de facto para esta fase es, desde hace años, _SonarQube(TM)_, el cual además se integra fácilmente con los gestores de proyectos más habituales (maven, gradle, npm..), hemos preferido integrar este producto en el presente ejemplo. Más adelante se explica en detalle este proceso.

==== Tests Unitarios

De nuevo Gitab se apoya en soluciones de terceros tanto para la ejecución de tests unitarios como SAST. En nuestro caso, emplearemos las capacidades embebidas en _maven_, más que suficientes en la mayor parte de los proyectos.

==== Construcción de Artefactos

La mayor parte de los gestores de proyectos (_maven_, _gradle_, _npm_..) disponen de sus propios mecanismos de detección de dependencias y construcción del/los artefactos finales. En este proyecto nos hemos apoyado en las capacidades de _maven_, como se verá más adelante. La adaptación de los jobs a otros entornos es bastante simple.

==== Registro de Artefactos

En este aspecto, el mercado está claramente dominado por dos jugadores clave: _Nexus(TM)_ y _Artifactory(TM)_. Gitlab, sin embargo, dispone de un "Package Registry" compatible con los formatos más habituales, y con funcionalidades básicas, que pensamos 
pueden ser suficientes en muchos casos. Por ello nos hemos basado en el propio Gitlab en este apartado.

==== Registro de Imágenes Docker

También en este apartado Gitlab dispone de un "Component Registry" muy flexible, por lo que es el que se ha empleado en este
ejemplo. Nótese que Nexus, por ejemplo, incorpora esta funcionalidad en un módulo adicional al Nexus Registry, lo que complica su empleo.

==== Provisionado

Gitlab dispone de imágenes docker con Git + Terraform, y es muy simple integrar _Terraform(TM)_ en los pipelines de gitlab. Las imágenes antes mencionadas incluyen una librería de integración con comandos del tipo 'gitlab-terraform xxxx'. No recomendamos el uso de esta librería, puesto que aporta poco y resulta algo farragosa. Por lo tanto, se ha creado una imagen docker ad-hoc basada en un linux mínimo (Alpine), y se emplean los comandos propios de Terraform.

Un aspecto muy interesante es que Gitlab puede actuar como backend del status Terraform del proyecto, evitando así que el eventual acceso simultáneo pueda provocar comportamientos indeseados. 

==== Despliegue

En esta primera versión, el despliegue de la imagen Docker generada se realiza de una manera relativamente simple (utilizando bash, sftp y ssh).
Gitlab puede integrar diferentes plataformas auxiliares tipo Helmet/Kubernetes, Ansible, etc. por lo que en posteriores versiones
de este proyecto se trabajará con estas posibilidades. 

=== Un vistazo a Gitlab CI/CD

Obviamente, no es objeto de este documento explicar pormenorizadamente el trabajo con Gitlab CI/CD, pero sí
que es interesante comentar los aspectos principales.

- Lo primero que llama la atención de Gitlab CI/CD es que existe un *único* archivo de definición
de pipelines por proyecto. Este archivo debe localizarse en la raíz del proyecto, y debe denominarse obligatoriamente ".gitlab-ci.yml". El
formato del archivo es yaml, con unas keywords bastante sencillas de aprender.
- No obstante lo anterior, este .yml puede contener "includes" de otro/s archivo/s .yml, los cuales a su vez pueden tener includes, y así sucesivamente.
Además, los includes pueden referenciar otro proyecto, por lo que es sencillo montar un proyecto específico para almacenar estos includes,
como es el caso de este ejemplo.
- El pipeline se compone de etapas (stages), y de definiciones de trabajos (jobs) asociados a las diferentes etapas. Puede haber más de un job asociado a un stage, bien sea para que se ejecuten en paralelo o úno sólo de ellos en función de los valores de ciertas variables.

image::img/stages.png[Etapas en Gitlab]

- Hay dos etapas predefinidas opcionales, llamadas ".pre" y ".post". Los jobs que se definan para estas etapas se ejecutarán siempre antes (después) que el resto de etapas.
- En cada job se definen reglas (rules) para incluir o no este job en el pipeline, y en qué condiciones de ejecución. Por ejemplo, un job "manual" quedará bloqueado en el pipeline hasta que sea lanzado por un Mantainer.
- Cuando se dispara un evento CI/CD, Gitlab analiza todas las reglas y monta de manera dinámica un pipeline que contiene sólamente los jobs en los que se cumplen las reglas. Esto nos permite tener "n" pipelines distintos, cada uno asociado a un conjunto de reglas. Como puede verse, se trata de una modalidad de trabajo muy diferente a la de Jenkins o Artifactory.
- También mediante reglas, podemos definir si permitimos o no que el job falle y, en consecuencia, que el pipeline continue. Por ejemplo, en un job que ejecute Sonar, permitimos que falle en la rama "develop", al no tratarse de un release a producción.
- Podemos incluir en el job un "before_script" y un "after_script", además del "script" principal. Por ejemplo, podemos definir un after_script que se debe ejecutar sólo si el job falla, para hacer rollout o preparar una fase posterior.
- En gitlab debemos tener uno o más "runners" que se encargan de gestionar la ejecución de los jobs, lanzando un "executor" específico para ese job. En este ejemplo, hemos configurado un runner tipo Docker, que se ejecuta como un container separado de Gitlab. Este runner, para cada job que se le asigna,
crea a su vez un container Docker con la imagen que se indique en el propio job, y es en este container donde se ejecutan los scripts, que se escriben en el lenguaje de shell asociado a la imagen docker, es decir, "sh", "bash", "PowerShell", etc.

image::img/runners.png[Runners y Executors]

- Para este ejemplo hemos preparado una imagen de executor denominada "ck-maven-executor", basada en un linux lightweight (Alpine) sobre el que se preinstalan maven, git y otros módulos de utilidad. De este modo, nos "ahorramos" todo el tiempo que requiere la instalación de estos componentes cada vez que ejecutemos un job. Adicionalmente se ha preparado otra imagen de executor denominada "ck-terraform-executor", también basada en Alpine y con Terraform preinstalado.
- Gitlab dispone de varios mecanismos para "pasar" información de un job a otro. Posiblemente el más usado es el "cache", en el que podemos incluir uno o más directorios de trabajo que cada job "lee" al inciarse y "escribe" al finalizar. Un ejemplo típico de uso es el repositorio de dependencias de maven. Si está en cache, se descargarán sólamente una vez y estarán a disposicion de los diferentes jobs.
- Un elemento clave en la definición del pipeline son las "variables". En Gitlab, existen varios niveles de variables:
* Variables predefinidas de Gitlab: Todas ellas comienzan con "CI_" y pueden contener tanto información estática como dinámica. Por ejemplo, CI_PROJECT_ID
contiene el ID del proyecto (estática), mientras que CI_COMMIT_REF_NAME contiene el nombre del branch sobre el que está trabajando el pipeline (dinámica).
* Variables de Grupo: Se definen en la configuración del grupo de proyectos. Pueden estar enmascaradas, para que no sean visibles en logs (p.e. passwords). Al estar asociadas al grupo, sólo los usuarios de nivel "Mantainer" en el grupo tienen derecho a visualizarlas y modificarlas. Aunque se trata de un mecaniso bastante simple, nos permite "ahorrarnos" un gestor de secretos (p.e. Vault) en las fases de CI/CD.
* Variables de Proyecto: Similares a las anteriores, sólo que específicas del proyecto
* Variables de Pipeline: Están asociadas al pipeline del proyecto y son modificables tanto por Mantainers como por Developers. Pueden definirse en alguno de los includes, o bien en el .yml principal.
* Variables de Job: Son específicas de cada job, y tienen vigencia sólo durante la ejecución de dicho job.
* Variables de Entorno: Específicas de cada script. Normalmente son variables de trabajo, aunque es posible pasarlas a jobs subsiguientes mediante el mecanismo de paso de artefactos "dotenv" que comentaremos más adelante.

- El pipeline se dispara al ocurrir determinados eventos (commit, push, merge_request). Tanto a nivel pipeline como individualmente por job podemos "filtrar" los eventos que nos interese. En este ejemplo, en las reglas a nivel pipeline hemos definido que sólo nos interesan los eventos "push".
- Gitlab dispone de muchos otros mecanismos (pipelines multiproyecto, triggers externos, webhooks, etc.) que no han sido necesarios en este ejemplo, por lo que no entramos en su descripción. 

== Descripción de las librerías

En esta primera versión del proyecto, empleamos únicamente tres productos: Gitlab, SonarQube y Terraform. Esto contrasta con los 4, 5 o 6 productos que se emplean habitulamnete en cadenas CI/CD. Estos tres productos, además, resultan muy familiares tanto a ingenieros DevOps como a desarrolladores.

En el proyecto se demuestra, además, que Gitlab CI/CD puede sustituir perfectamente a Jenkins o TeamCity, y con un lenguaje de definición de pipelines muy simple y de rápida curva de aprendizaje.

=== Layout

Se ha creado un proyecto Git denominado "cicd-librerias" dentro del grupo de proyectos "comunytek". En este grupo de proyectos se encuentra también el proyecto "selfwebspringboot" que usaremos como ejemplo de la implementación de las librerías.

- En _cicd-librerias_ se han creado 3 carpetas:

* ejemplos_cfg: Incluye ejemplos de configuraciones en los proyectos base, tales como ".gitlab-ci.yml", "pom.xml", etc.
* pipelines: Contiene los includes principales para los diferentes entornos. En la actual versión sólo está definido el relativo a maven/java.
* jobs: Contiene una carpeta para cada entorno (en este ejemplo, solamente maven), y en cada carpeta, los includes de cada job del pipeline.

- En _selfwebspringboot_ se ha creado el archivo ".gitlab-ci.yml", como ejemplo de integración de las librerías _cicd-librerias_.

Este sería el esquema básico de empleo de las librerías:

image::img/layout.png[Layout]

=== Variables

==== De Grupo

A nivel del grupo de proyectos (en este caso "comunytek") es necesario definir las siguientes variables:

CICD_USER:: Usuario de gitlab con suficientes derechos para llamar a la API de Gitlab en relación al proyecto. Normalmente será un Mantainer.
CICD_PASSWD:: Password del usuario anterior.
CICD_TOKEN:: Personal token creado para el usuario anterior (en settings de usuario).
CICD_EMAIL:: Dirección de correo del usuario anterior.
CICD_HOST:: Nombre del host donde se encuentra instalado Gitlab (p.e. "git2.comunytek.com").
CICD_REGISTRY_HOST:: Nombre del host para el acceso al registry Docker. Aunque se trata del propio Gitlab, atiende a un puerto distinto, por lo que hemos de discriminarlo por el nombre del host (p.e. "https://registry2.comunytek.com").
SONAR_HOST_URL:: Url completa del host donde está instalado Sonarqube (p.e. "https://sonar2.comunytek.com").
SONAR_HOST_TOKEN:: Token generado en Sonar para acceso externo mediante la API.

==== De pipeline (ocultas)

En el include principal del pipeline se definen un conjunto de variables que quedan ocultas para los Developers, y que se han utilizado como base para implementar los diferentes flujos. Un Manager de Grupo puede modificar el comportamiento del pipeline sin más que actualizar estas variables.

IGNORE_AUX_BRANCHES:: No ejecutar el pipeline en ramas auxiliares (aquellas distintas de 'master' y 'develop').
Si se define a "true", el resto de flags relacionados con ramas auxiliares no tienen efecto.
Como excepcion, la rama identificada como HOTFIX_BRANCH (si existe) siempre pasa.
COMPILE_AUX_BRANCHES:: Compilar o no ante un push en ramas auxiliares.
SONAR_AUX_BRANCHES:: Pasar o no Sonar en ramas auxiliares. En cualquier caso se admite que falle.
TEST_AUX_BRANCHES:: Pasar o no test unitarios en ramas auxiliares. En cualquier caso se admite que falle.
ALLOW_FAILURE_IN_SONAR_DEVELOP:: Permitir fallo al pasar Sonar en rama develop.
ALLOW_FAILURE_IN_TEST_DEVELOP:: Permitir fallo al pasar tests unitarios en rama develop.
ALLOW_RELEASE_IN_DEVELOP:: Permitir versiones release (no son SNAPSHOT) en rama develop. Normalmente será "false", pero puede haber circunstancias específicas en que sea necesario permitirlo. Nótese que nunca permitimos versiones SNAPSHOT en rama master.
REGISTER_DEVELOP:: Registrar, generar imagen docker y tag de la rama 'develop'. Debe indicarse a "true"
si la rama 'develop' representa despliegues oficiales en preproducción, UAT, QA o staging.
Si se establece como "false", el pipeline termina con la generación del fat-jar y su
almacenamiento temporal como artefacto.
PROVISION_DEVELOP:: Provisionar infraestructura (Terraform) en rama develop.
DEPLOY_DEVELOP:: Instalar/actualizar software en rama develop.
TF_BACKEND_ADDRESS:: URL del backend de Terraform (sólo aplica si se ha activado el provisioning con Terraform). Normalmente será "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/terraform/state/${CI_COMMIT_REF_NAME}".

==== Del proyecto

Se trata de variables con valores específicos para cada proyecto, pero que sólo deben ser editables por usuarios de nivel "Mantainer". Se definen en los settings CI/CD del proyecto.

===== Específicas para provisionado con Terraform 

TF_ROOT:: Directorio raiz de la configuracion de Terraform. Normalmente se definirá en base a variables intrínsecas de Gitlab. P.e "$CI_PROJECT_DIR/terraform/$CI_COMMIT_REF_NAME". 
TF_VAR_HYPERVISOR_USER:: Usuario de login del host donde reside el hipervisor. En el caso de AWS, Access key ID.
TF_VAR_HYPERVISOR_PASSWD:: Password de dicho usuario. En el caso de AWS, Secret acess key.

===== Específicas para despliegue como stack Docker

DEPLOY_SSH_USER:: Usuario a emplear para conectar por SSH con la VM creada
DEPLOY_SSH_KEY:: Variable tipo 'File' que contiene la clave privada para acceder por SSH a la nueva VM
DEPLOY_SSH_PATH:: Path donde vamos a instalar/actualizar el producto
DEPLOY_SSH_SVC_NAME:: Nombre del servicio docker que vamos a crear/instalar

==== De pipeline (editables)

Se trata de variables definidas en el ".gitlab-ci.yml" del proyecto y que son, por tanto, editables por los Developers, para tratar circunstancias específicas.

SNAPSHOT_NUMBER:: Si registramos, creamos docker y tag, etc. en SNAPSHOT podemos agregar (opcionalmente)
un numero de snapshot a la vesion del proyecto para identificar registros y tag. Nótese que, si la versión en el pom junto con este indentificador ya está registrada, el job de registro terminará con error, y el pipeline se interrumpirá.
HOTFIX_BRANCH:: Indicar la rama de hotfix en la que estamos trabajando, si es que existe. En esta rama, se ejecuta todo el pipeline,
aunque las etapas sonar y test admiten errores.
Comentar esta linea, o dejar en blanco el valor, una vez liberado el hotfix.
HOTFIX_NUMBER:: Opcionalmente, podemos indicar un numero de hotfix, para registro, docker y tag.
En la version del proyecto, se respeta la que se indica en el pom.xml.
RUN_CI_STAGES:: "true"/"false". Indica si se deben ejecutar las etapas asociadas a integración continua (CI).
RUN_REGISTER_STAGES:: "true"/"false". Indica si se deben ejecutar las etapas asociadas al registro de artefactos, imágenes docker y tags.
RUN_PROVISION_STAGES:: "true"/"false". Indica si se deben ejecutar las etapas asociadas al provisioning de infraestructura.
RUN_DEPLOY_STAGES:: "true"/"false". Indica si se deben ejecutar las etapas asociadas al despliegue (instalación/actualización) del software.

=== Pipeline del proyecto e include principal

En el proyecto _selfwebspringboot_ se ha creado el archivo ".gitlab-ci.yml" con el contenido siguiente:

------------------------------------------------------------
variables:
  SNAPSHOT_NUMBER: "005"
  HOTFIX_BRANCH: ""
  HOTFIX_NUMBER: "002"
  ....

include:
   project: 'comunytek/cicd-librerias'
   ref: master
   file: 'pipelines/maven-springboot-simple.yml'
------------------------------------------------------------

Como puede verse, simplemente se definen las variables de pipeline editables, y se incluye el resto de la definición del pipeline tomada del proyecto _cicd-librerias_.

El include principal sólo es editable por Managers de Grupo. En este ejemplo, mostramos a continuación un extracto de su contenido.

------------------------------------------------------------
variables:
  SONAR_USER_HOME: "${CI_PROJECT_DIR}/.sonar"    # Home de sonar, para caching
  ...

workflow:
  rules:
    - if: $CI_COMMIT_TAG        # No ejecutar en tags                   
      when: never
  ...

image: ck-maven-executor:1.0.1     # Imagen por defecto

cache:
  key: "$CI_COMMIT_REF_NAME"

# Etapas posibles del pipeline
stages:
  - prepare
  - compile
  
  ...
# Includes, uno por job
include: 
  - project: 'comunytek/cicd-librerias'
    ref: master
    file: 
      - 'jobs/maven/prepare-simple.yml'
      - 'jobs/maven/compile-simple.yml'
      ... resto de includes
------------------------------------------------------------

=== Fases del pipeline

A efectos de control global del flujo, se han agrupado las diferentes etapas en la siguientes fases:

* Preparación
- create-bash-library
- prepare
* Integración continua (CI)
- compile
- sonar
- test
- build
* Registro (artefacto, imagen docker, tag)
- register
- docker
- tag
* Aprovisionamiento de infraestructura
- tf-prepare
- tf-apply
* Despliegue del producto
- deploy

=== Jobs específicos para maven

A continuación se explica brevemente la funcionalidad de los diferentes jobs. Puede accederse al código fuente siguiendo el correspondiente link. Los jobs se muestran agregados por fases e indicando, si es necesario, la etapa (stage) a la que corresponden. 

==== Fase de preparación

Se ejecuta de manera incondicional, y se emplea para preparar la caché, así como algunas variables de entorno que serán de utilidad en etapas posteriores.

===== _Create-bash-library (.pre)_

Job definido en link:jobs/maven/create-bash-library.yml[]. Se ejecuta en la etapa ".pre", es decir, con anterioridad a cualquier otro job del pipeline. En este caso concreto, se limita a crear y popular un archivo temporal llamado "funciones-bash.sh" conteniendo una serie de funciones escritas en bash y de uso general para cualquier job del pipeline. El archivo generado se pasa como artefacto al resto del pipeline. Cuando un job quiere llamar a una función de la librería, necesita "cargarla" previamente, lo que se hace habitualmente en el before_script:

------------------------------------------------------------
  before_script:
    - . funciones-bash.sh
------------------------------------------------------------

Este mecanismo permite mantener la/s librería/s bajo control de código fuente, y es el recomendado por Gitlab.

===== _Prepare (prepare)_

Para esta etapa se ha definido el job en el archivo link:jobs/maven/prepare-simple.yml[]. Este job se ejecuta incondicionalmente en todas las
ramas al hacer push, excepto en ramas auxiliares si el flag IGNORE_AUX_BRANCHES está a true (todo el pipeline simplemente se ignora). El job prepara el entorno para la ejecución de jobs posteriores.

- Define los directorios que forman parte del cache.
- Calcula una serie de variables de entorno, útiles para todo el pipeline.
- Copia las claves y valores de las variables de entorno a un archivo temporal "prepare.env".
- Pasa el contenido de "prepare.env" al resto del pipeline mediante un artefacto de tipo "reports" y clave "dotenv". Las variables contenidas en este archivo son accesibles en todo el pipeline.

==== Fase de integración contínua (CI)

===== _Compile_

El job en se define en link:jobs/maven/compile-simple.yml[]. Se ejecuta incondicionalmente en todas las ramas al hacer push, excepto en ramas auxiliares si el flag COMPILE_AUX_BRANCHES está a false (o bien el flag IGNORE_AUX_BRANCHES está a true, lo que aplica a todo el pipeline). También se ejecuta en la rama hotfix (si existe). En este ejemplo, el job es bastante simple:

- Define los directorios de la cache.
- Ejecuta "mvn clean compile". Si se produce un error de compilación, el pipeline se detiene.

===== _Sonar_

Para esta etapa se ha definido el job en el archivo link:jobs/maven/sonar-simple.yml[]. Se ejecuta incondicionalmente en todas las ramas al hacer push, excepto en ramas auxiliares si el flag SONAR_AUX_BRANCHES está a false. También se ejecuta en la rama hotfix (si existe). Se ejecuta Sonarqube sobre el código fuente para localizar bugs, code-smells y vulnerabilidades SAST.

- Se permite continuar en caso de error en hotfix y ramas auxiliares, así como en develop siempre que el flag ALLOW_FAILURE_IN_SONAR_DEVELOP se defina como true.
- En ramas auxiliares se pasa Sonar sólo en archivos modificados, mientras que en el resto de ramas se pasa a todo el código. 
- Se ejecuta "mvn validate sonar:sonar".

===== _Test_

Job definido en link:jobs/maven/test-simple.yml[]. Se ejecuta incondicionalmente en todas las ramas al hacer push, excepto en ramas auxiliares si el flag TEST_AUX_BRANCHES está a false. Nótese que en la rama hotfix (si existe) también se ejecuta este job. El objetivo del job es pasar los test unitarios definidos para el proyecto.

- Se permite continuar en caso de error en hotfix y ramas auxiliares, así como en develop siempre que el flag ALLOW_FAILURE_IN_TEST_DEVELOP se defina como true.
- Se ejecuta "mvn test".

===== _Build_

Para esta etapa se ha definido el job en el archivo link:jobs/maven/build-simple.yml[]. Este job se ejecuta incondicionalmente en master, develop y hotfix al hacer push. No se ejecuta en ramas auxiliares. Se trata de construir el artefacto objeto del proyecto. En el caso de maven/SpringBoot se trataría del llamado "fat-jar".

- Se ejecuta "mvn package". Si da error, se detiene el pipeline.
- Si estamos en la rama master y la versión del proyecto es SNAPSHOT, salimos con error 2 (no se permite SNAPSHOT en master).
- Si estamos en la rama develop, la versión del proyecto NO es SNAPSHOT y el flag "ALLOW_RELEASE_IN_DEVELOP" es false, salimos con error 3 (no se permite release en develop).
- Si estamos en develop y el flag REGISTER_DEVELOP es false, salimos con error 4 (la rama develop no se registra), con lo que detenemos el pipeline.
- Si salimos con error, generamos un artefacto compuesto por el fat-jar, el pom y el .gitlab-ci.yml. Este artefacto está disponible para su descarga durante un periodo de 8 horas. La idea es que, si se genera alguno de los errores anteriores, el pipeline se detenga, pero dispongamos del artefacto para pruebas adicionales, condiciones no contempladas, etc.

==== Fase de registro

===== _Register_

Job definido en link:jobs/maven/register-simple.yml[]. Se ejecuta en master, hotfix y develop (si el flag REGISTER_DEVELOP es true) al hacer push. No se ejecuta en ramas auxiliares. Este job asume que se ha ejecutado la etapa "build" y diponemos, por tanto, del "fat-jar" en la cache. Para que el job ejecute con éxito, se precisan unos requisitos previos:

- Habilitar (si no lo está) el "Package Registry" de Gitlab y configurarlo para que no acepte duplicados.
- Configurar, en el pom.xml, los registries para snapshot y release (dentro del elemento <distributionManagement>).
- Crear un archivo "ci_settings.xml" definiendo las credenciales de acceso a el/los registries.
- En el directorio "ejemplos_cfg/maven" pueden verse ejemplos para un proyecto real.

Este job (como otros varios del pipeline) se ha definido como "manual". Esto significa que queda bloqueado dentro de la cadena de ejecución hasta que se libere manualmente. En gitlab, no existe, por el momento, un mecanismo directo de interacción con la consola pero podemos, de forma indirecta, controlar el flujo:

image::img/jobmanual.png[Job manual]

Por ejemplo, en este caso, se ha definido una variable de job llamada SKIP, con valor inicial false. Si en el job pulsamos el icono de "play", la variable no cambiará su valor. Por contra, si pulsamos sobre el nombre del job, se nos presenta un formulario en el que podemos agregar o modificar el valor de variables locales.
En este ejemplo, podemos definir la variable SKIP a true, con lo que podemos, en el script, saltanos la ejecución de este job y pasar a la siguiente etapa:

-------------------------------------------------
  variables:
    SKIP: "false"
  script:
    - '[[ ${SKIP} == "true" ]] && { echo "WARN: Ha entrado SKIP=true, asi que saltamos esta etapa."; exit 0; }'

-------------------------------------------------


El job prepara un artifact ID del siguiente modo:

- En rama master, el ID es la versión del proyecto en el pom (debe ser de release). Como es lógico, no puede registrarse la misma versión más de una vez.
- En rama develop, y si es SNAPSHOT, se agrega a la versión del proyecto el valor de la variable SNAPSHOT_NUMBER, con lo quedaría algo como "5.0.6-SNAPSHOT.003". De este modo, podemos liberar para UAT o staging más de una versión intermedia, en forma de "release candidate", pero manteniendo registrada toda la historia de este SNAPSHOT.
- En rama develop, si NO es SNAPSHOT, y aceptamos release en develop (variable ALLOW_RELEASE_IN_DEVELOP a true), agregamos a la versión del proyecto la cadena "-DEVELOP-RELEASE" seguida del SNAPSHOT_NUMBER, es decir, algo como "5.0.6-DEVELOP-RELEASE.003". Es una situación bastante rara, puesto que se sale de la normativa básica de flujo, pero hemos dejado abierta esta posibilidad para acomodar circunstancias excepcionales.
- En rama hotfix (si existe), agregamos a la versión del proyecto la cadena "-HOTFIX" seguida del HOTFIX_NUMBER, es decir, algo como "5.0.6-HOTFIX.002".

Finalmente, creamos un tar con los fuentes y registramos un artefacto compuesto por el fat-jar, el pom y el tar:

----------------------------------------------------
      SRC_FILE="./{PRJ_VERS}-src.tgz"
      tar czf ${SRC_FILE} ./src/*
      mvn validate deploy:deploy-file -s ci_settings.xml \
      -Durl="${REG_URL}" \
      -DrepositoryId="gitlab-maven" \
      -Dfile="${JAR_FILE}" \
      -DpomFile="pom.xml" \
      ${VERSION} \
      -Dfiles=${SRC_FILE} \
      -Dclassifiers=src \
      -Dtypes=tgz
----------------------------------------------------

===== _Docker_

Para esta etapa se ha definido el job en el archivo link:jobs/maven/docker-simple.yml[]. Este job se ejecuta incondicionalmente en master y hotfix al hacer push. No se ejecuta en ramas auxiliares. Adicionalmente puede ejecutarse en develop si REGISTER_DEVELOP es true. Sólo se ejecuta si existe, en la raiz del proyecto, un archivo "Dockerfile".

El job prepara un Image ID del siguiente modo:

- En rama master, agregamos al Id base la cadena "/release". Nótese que el Component Registry SI admite duplicados.
- En rama develop, y si es SNAPSHOT, se agrega al Id base la cadena "/snapshot", y a la versión de proyecto el SNAPSHOT_NUMBER.
- En rama develop, si NO es SNAPSHOT, y aceptamos release en develop (variable ALLOW_RELEASE_IN_DEVELOP a true), agregamos al Id base cadena "/develop-release", y a la versión de proyecto el SNAPSHOT_NUMBER.
- En rama hotfix (si existe), agregamos al Id de base la cadena "/hotfix", y a la versión de proyecto el HOTFIX_NUMBER.

El job guarda el IMG_TAG generado en el archivo "prepare.env", y lo pasa como artefacto a etapas posteriores. Además:

- Crea la imagen Docker en base al Dockerfile.
- Hace login al Component Container de nuestro Gitlab.
- Registra la imagen mediante "docker push".

-------------------------------------------------
    - 'echo "IMG_TAG=${IMG_TAG}" >> prepare.env'
    - docker -v
    - 'echo "$CICD_PASSWD" | docker login -u $CICD_USER --password-stdin $CICD_REGISTRY_HOST'
    - docker build -t $IMG_TAG .
    - docker push $IMG_TAG 
-------------------------------------------------

===== _Tag_

Job definido en link:jobs/maven/tag-simple.yml[]. Se ejecuta en master, hotfix y develop (si el flag REGISTER_DEVELOP es true) al hacer push. El job se ha definido como "manual".

El job computa un TagID, de acuerdo los siguientes criterios:

- Si estamos en la rama master, el TagID se forma con la cadena "release-" seguida de la versión del proyecto, es decir, algo como "release-5.0.6".
- En rama develop, y si es SNAPSHOT, se forma con la cadena "snapshot-", la versión de proyecto y el SNAPSHOT_NUMBER. Algo como "snapshot-5.0.6-SNAPSHOT.003".
- En rama develop, si NO es SNAPSHOT, y aceptamos release en develop (variable ALLOW_RELEASE_IN_DEVELOP a true), se forma con cadena "develop-release-", la versión de proyecto y el SNAPSHOT_NUMBER. Algo como "develop-release-5.0.6.003".
- En rama hotfix (si existe), se forma con la cadena "hotfix-", la versión de proyecto y el HOTFIX_NUMBER. Algo como "hotfix-5.0.6.002".

Con este Id se genera un tag. Nótese que los TagID no pueden repetirse. 

-------------------------------------------------
    - git config user.name "$CICD_USER"
    - git config user.email "$CICD_EMAIL"
    - git remote remove origin
    - git remote add origin ${ORIGIN_URL}
    - git tag -a $TAG -m "Build $TAG"
    - git push origin $TAG
-------------------------------------------------

==== Fase de aprovisionamiento de infraestructura

En la versión actual de la librería se emplea Hashicorp _Terraform(TM)_ como gestor en la infraestructura. La librería es agnóstica en cuanto a la plataforma
de provisioning u otros detalles, que deberán definirse en archivos y módulos de Terraform. Para que el job funcione correctamente, en el proyecto debe
definirse una variable llamada TF_ROOT apuntando al directorio raiz de la configuración a emplear. Por ejemplo, si vamos a manejar infraestructura en Amazon AWS, y
queremos diferenciar las configuraciones de pre-producción y producción podríamos usar:

TF_ROOT=$CI_PROJECT_DIR/terraform/aws/$CI_COMMIT_REF_NAME

En el directorio ejemplos-cfg puede verse un ejemplo de configuración, en este caso, para Hyper-V.

===== _Tf-prepare_

Se ha definido en link:jobs/maven/tf-prepare-simple.yml[]. Se ejecuta en master y, opcionalmente en develop, siempre que el flag PROVISION_DEVELOP esté a "true".

Se emplea como backend de estado el propio gitlab, para lo que se requiere establecer los datos de acceso al mismo mediante las variables TF_BACKEND_ADDRESS (debe definirse a nivel de grupo), TF_HYPERVISOR_USER y TF_HYPERVISOR_PASSWD (estas últimas a nivel de proyecto).

El job valida la configuración de terraform y crea el "plan" de provisionado en base a los posibles cambios sobre la situación real de máquinas, discos, interfaces, etc. El plan generado se pasa a las etapas posteriores en forma de artefacto interno del pipeline.

===== _Tf-apply_

Job definido en link:jobs/maven/tf-apply-simple.yml[]. Se ejecuta en master y, opcionalmente en develop, siempre que el flag PROVISION_DEVELOP esté a "true". Definido como "manual" para permitir la revisión detallada el plan preparado en la etapa anterior, antes de proceder al provisioning (apply). Como todos los jobs manuales de esta librería, podemos "saltarnos" la ejecución sin más que indicar SKIP=true antes de lanzarlo.

Adicionalmente, se ha previsto la posibilidad de realizar una acción cualquiera de terraform, para lo que debemos definir la variable ACTION con el valor deseado. Por defecto es "apply", pero podemos entrar "destroy" u otro comando terraform válido.

Con el fin de facilitar la posterior fase de despliegue, los _outputs_ de Terraform se escriben en un archivo llamado "cicd.vars", que se ha definido como parte de la caché, y tiene el formato "key=value", por lo que puede leerse fácilmente en forma de variables de entorno en etapas posteriores, sin más que emplear
"source cicd.vars" en el script. Al formar parte de la caché, se persiste entre una invocación y otra del pipeline. Por ejemplo, si uno de los outputs es la IP
de la máquina provisionada, se guardará en caché, con lo que podemos ejecutar el pipeline una vez con los flags
RUN_PROVISION_STAGES="true" y RUN_DEPLOY_STAGES="false" y, si todo ha ido bien, lanzar más tarde el pipeline con RUN_PROVISION_STAGES="false" y RUN_DEPLOY_STAGES="true",
y la/s etapa/s de deploy podrán obtener los outputs de Terraform desde el archivo cacheado _cicd.vars_. 

==== Fase de despliegue (instalación/actualización) del producto

===== _Deploy_

Para esta etapa se ha definido el job en el archivo link:jobs/maven/deploy-simple.yml[]. Se ejecuta en master y, opcionalmente en develop, siempre que el flag DEPLOY_DEVELOP esté a "true". Definido como "manual" para que pueda lanzarse sólamente una vez verificado que el provisionado ha sido correcto.

A fin de que la librería sea genérica, el job se ha planteado de manera muy simple:

- A nivel de proyecto, debe definirse una variable DEPLOY_ROOT apuntando a un directorio que contenga todo lo necesario para hacer el deploy. Por ejemplo:
DEPLOY_ROOT=$CI_PROJECT_DIR/deploy/$CI_COMMIT_REF_NAME.
- Tambien a nivel de proyecto deben definirse las variables DEPLOY_SSH_USER, DEPLOY_SSH_KEY, DEPLOY_SSH_PATH y DEPLOY_SSH_SVC_NAME, cuyo significado se ha explicado
en párrafos anteriores.
- En este directorio debe existir un archivo "exec_deploy.sh" conteniendo las funciones bash que se precisen y, obligatoriamente, una
denominada "exec_deploy", que será la que se ocupe de realizar el deploy propiamente dicho, ya sea simplemente con SSH o empleando algún agente externo,
tipo _ansible(TM)_ o similar.

En el ejemplo que venimos tratando, la función copia al remoto todo el directorio de deploy, que consiste en lo siguiente (ver directorio "deploy" en los ejemplos):

- Un archivo "docker-compose.yml" que define el stack docker en el que se ejecutará el producto. En este archivo hay un "placehorder" donde debemos indicar la imagen docker a instalar, que se habrá generado y registrado en la etapa "docker". Este placeholder se rellena mediante un archivo "docker-compose.override.yml" que se genera de manera automática en tiempo de despliegue, y que tendrá un contenido similar al siguiente:

-------------------------------------------------
services:
    selfweb:
        image: registry2.comunytek.com/comunytek/selfweb/selfwebspringboot/release:5.0.6
-------------------------------------------------

- Un árbol de directorios en los que definimos los "volumes" y "networks" que empleará el stack. Cuando alguno de los volúmenes se debe crear, pero no copiar su contenido al destino, debe incluir un archivo llamado "ignore". Si no es así, todo el contenido se copia (y sobrescribe) al destino (/var/lib/docker/volumes/xxx/_data).
- Un script bash llamado "deploy.sh" que se ejecutará de manera remota y se ocupará de realizar la instalación propiamente dicha (ver ejemplos).

== Casos de uso

Para los casos de uso que siguen, se parte de la siguiente configuración de variables:

*De pipeline (grupo)*

* IGNORE_AUX_BRANCHES: "false"
* COMPILE_AUX_BRANCHES: "true"
* SONAR_AUX_BRANCHES: "true"
* TEST_AUX_BRANCHES: "false"
* ALLOW_FAILURE_IN_SONAR_DEVELOP: "false"
* ALLOW_FAILURE_IN_TEST_DEVELOP: "false"
* ALLOW_RELEASE_IN_DEVELOP: "false"
* REGISTER_DEVELOP: "true"
* PROVISION_DEVELOP: "false"
* DEPLOY_DEVELOP: "false"

*De pipeline (proyecto)*

* SNAPSHOT_NUMBER: "003"
* HOTFIX_BRANCH: "Hotfix-Issue-23056"
* HOTFIX_NUMBER: "002"
* RUN_CI_STAGES: "true"
* RUN_REGISTER_STAGES: "true"
* RUN_PROVISION_STAGES: "true"
* RUN_DEPLOY_STAGES: "true"

=== Ramas auxiliares

Habitualmente un único desarrollador trabajará en la rama "X", en su PC personal, y con un repositorio git local clonado inicialmente desde el servidor Gitlab.

- Periódicamente, hará commit  de los cambios realizados a su repositorio local.
- Sea por razones de backup, por haber finalizado un sprint, etc., hará push de la rama auxiliar, lo que disparará el pipeline.
- Dado que IGNORE_AUX_BRANCHES es false, el pipeline se ejecuta, con los stages:
* create_bash_library: Comportamiento normal
* prepare: Comportamiento normal.
* compile: Se ejecuta, al ser COMPILE_AUX_BRANCHES = true.
* sonar: Se ejecuta, al ser SONAR_AUX_BRANCHES = true. Se pasa sonar sólo a los archivos modificados y se permite errores.
* NO se ejecuta la etapa test, al ser TEST_AUX_BRANCHES = false.

Como puede verse, se trata símplemente de verificar que el código fuente actual compila sin errores y pasa o no sonar.

=== Rama develop

El tratamiento de esta rama es bastante más complejo, puesto que en su desarrollo pueden intervenir varias personas. Además, si el flag REGISTER_DEVELOP es true, probablemente vamos a hacer un despliegue "oficial" a UAT o staging, por lo que hemos de ser cuidadosos.

- A medida que los desarrolladores van finalizando su trabajo en su rama "X, Y,..", hacen lo siguiente:
* Hacen fetch / diff / pull de la rama develop (o eventualmente de una rama temporal específica para el sprint), para obtener el último código disponible.
* Hacen merge (en local) de su rama "X" sobre develop/sprint. Si hay conflictos, deben resolverse en la rama "X" y repetir el proceso.
* Notifican al Project Leader que su trabajo está concluido, al menos provisionalmente.
* El proceso se repite hasta tener finalizada la versión o sprint, pasados los tests de integración y cualquier otro requisito previo y, en definitiva, poder pasar a pre-producción.

- El Project Leader, una vez finalizadas todas las ramas que conforman la versión o sprint, hace lo siguiente:
* Hace pull de develop a su repositorio local.
* Para cada una de las ramas auxiliares que conforman el SNAPSHOT (o bien para la rama de sprint) hace merge en local de dicha/s rama/s sobre develop. Si todavía quedan conflictos, deben resolverse entre los desarrolladores, y repetir el circuito.
* Una vez resueltos los conflictos, actualiza el pom de develop con la versión fijada para el SNAPSHOT. Si admitimos snapshots incrementales, se define el número de snapshot en la variable SNAPSHOT_NUMBER.
* Hace push de la rama develop, lo que dispara el pipeline.

- Con la configuración antes descrita, el pipeline funcionará del siguiente modo:

* create_bash_library: Comportamiento normal
* prepare: Comportamiento normal.
* compile: Comportamiento normal.
* sonar: Se pasa para todo el código, y NO se admiten errores (ALLOW_FAILURE_IN_SONAR_DEVELOP = false).
* test: Se pasan tests unitarios, y NO se admiten errores (ALLOW_FAILURE_IN_TEST_DEVELOP = false).
* build: Se crea el "fat-jar" y, posteriormente, se verifican condiciones para continuar el pipeline. Si no se cumplen, se genera un artefacto con el .jar y el pom, el cual queda disponible para download durante unas horas. Una de las condiciones para continuar es que REGISTER_DEVELOP valga true. Si, a pesar de estar en la rama develop, la versión del proyecto NO es SNAPSHOT, y dado que ALLOW_RELEASE_IN_SNAPSHOT es false, el pipeline se interrumpirá.
* register: Se registra un artefacto compuesto por el fat-jar, el pom y un tgz conteniendo los fuentes actuales en el "Package Registry" de gitlab. El Id del artefacto no puede repetirse, y así el artefacto se convierte en el "single source of truth" de las diferentes versiones registradas. En este ejemplo, al tratarse de un registro tipo maven, podría (si se tratase de una líbrería) emplearse como dependencia en otros proyectos.
* docker: Sólo si se trata de un proyecto docker. Se genera la imagen docker y se registra en el "Container Registry" de gitlab.
* tag: Se crea un nuevo Tag con Id único que incluye el SNAPSHOT_NUMBER.
* tf-prepare: NO se ejecuta (PROVISION_DEVELOP: "false").
* tf-apply: NO se ejecuta (PROVISION_DEVELOP: "false").
* deploy: NO se ejecuta (DEPLOY_DEVELOP: "false").

=== Rama master

En el modelo de flujo que hemos seleccionado, la rama master contiene únicamente la última versión para producción (release). Es por ello que el trabajo sobre esta rama es muy delicado, estando su manejo reservado a usuarios de nivel Mantainer y, preferentemente, al Project Leader.

- Una vez que último SNAPSHOT ha sido aprobado, el Project Leader hace lo siguiente:
* Hace pull de develop a su repositorio local, y se asegura de que se trata de la versión SNAPSHOT aprobada para producción.
* Para evitar errores, hace pull de master, y comprueba que se trata de la última versión de release.
* Hace merge de develop sobre master, y resuelve los eventuales conflictos con la ayuda del resto del equipo.
* Modifica la versión del proyecto en master para eliminar la cadena "-SNAPSHOT".
* Hace push de master, lo que dispara el pipeline.

- Con esta configuración, el pipeline funcionará del siguiente modo:

* create_bash_library: Comportamiento normal
* prepare: Comportamiento normal.
* compile: Comportamiento normal.
* sonar: Se pasa para todo el código, y NO se admiten errores.
* test: Se pasan tests unitarios, y NO se admiten errores.
* build: Se crea el "fat-jar" y, se verifica que la versión del proyecto NO es SNAPSHOT. Si no se cumple, se genera un artefacto con el .jar y el pom, el cual queda disponible para download durante unas horas y se interrumpe el pipeline.
* register: Se registra un artefacto compuesto por el fat-jar, el pom y un tgz conteniendo los fuentes actuales en el "Package Registry" de gitlab. El Id del artefacto no puede repetirse, y así el artefacto se convierte en el "single source of truth" de las diferentes versiones registradas. En este ejemplo, al tratarse de un registro tipo maven, podría (si se tratase de una líbrería) emplearse como dependencia en otros proyectos.
* docker: Sólo si se trata de un proyecto docker. Se genera la imagen docker y se registra en el "Container Registry" de gitlab.
* tag: Se crea un nuevo Tag con Id único (la versión del proyecto).
* tf-prepare: Inicializa el backend de terraform y crea el plan de provisioning.
* tf-apply: Se ejecuta de forma manual. Aplica el plan terraform anteriormente generado.
* deploy: Sólo si se trata de un proyecto docker. Se ejecuta de forma manual. Se instala o actualiza el producto en entorno de producción.

=== Rama hotfix

En esta versión se ha dejado bastante libertad al tratamiento de eventuales ramas hotfix, puesto que cada organización tiene su propia normativa, que deberá implementarse en la definición final del pipeline.

- Si es preciso crear y liberar un hotfix, se procederá del siguiente modo:
* El project leader creará, a partir del tag de la versión de release implicada, una nueva rama, designada de acuerdo con la normativa de la organización (p.e. "Issue-#"). Para que la nueva rama sea considerada hotfix, se modificará la variable HOTFIX_BRANCH para que contenga el nombre de dicha rama. El HOTFIX_NUMBER se definirá con un valor inicial, p.e. "001" que se deberá ir incrementando para cada hotfix requerido en la versión implicada.
* El desarrollo del parche se realizará bien en la propia rama de hotfix (si se trata de un trabajo de menor cuantía), o bien en una o más ramas auxiliares con las que después de hará merge sobre la de hotfix.
* Una vez finalizado el hotfix, se hará push de su rama, lo que disparará el pipeline.
* Nótese que, dependiendo de la normativa de la organización, los cambios realizados o bien se repetirán sobre el trabajo en curso en SNAPSHOT, o bien se incluirá la rama hotfix en una de las que se hará merge sobre develop antes de liberar el SNAPSHOT.
* Una vez finalizado el pipeline con éxito, lo normal es que se elimine la rama de hotfix.

- Con la configuración antes indicada, el pipeline funcionará del siguiente modo:

* create_bash_library: Comportamiento normal
* prepare: Comportamiento normal.
* compile: Comportamiento normal.
* sonar: Se pasa para todo el código, y SI se admiten errores.
* test: Se pasan tests unitarios, y SI se admiten errores.
* build: Se crea el "fat-jar" y no se hacen más comprobaciones.
* register: Se registra un artefacto compuesto por el fat-jar, el pom y un tgz conteniendo los fuentes actuales en el "Package Registry" de gitlab. El Id del artefacto no puede repetirse, por lo que a la versión del proyecto se agrega el HOTFIX_NUMBER, y el artefacto se convierte en el "single source of truth" de las diferentes versiones hotfix registradas. En este ejemplo, al tratarse de un registro tipo maven, podría (si se tratase de una líbrería) emplearse como dependencia en otros proyectos.
* docker: Sólo si se trata de un proyecto docker. Se genera la imagen docker y se registra en el "Container Registry" de gitlab.
* tag: NO se ejecuta.
* tf-prepare: NO se ejecuta.
* tf-apply: NO se ejecuta.
* deploy: NO se ejecuta.

== Conclusión

En el presente proyecto se ha comprobado que es posible obtener un ahorro importante, tanto en horas/hombre como en curva de aprendizaje, empleando Gitlab CI/CD como herramienta básica del proceso, frente a otras soluciones multi-producto, aunque, lógicamente, no se llegue al nivel de sofisticación y complejidad que pueden aportar las mismas. Adicionalmente, la definición de pipelines realizada, si bien es sólo un ejemplo, puede emplearse como "template" y adaptarse a los requisitos de muchas organizaciones.

Se han incorporado, además, etapas de provisionado y despliegue relativamente sofisticadas, empleando _Terraform(TM)_, ssh, sftp y bash, que son más que suficientes para muchas situaciones reales. 
