= Proyecto _cicd-librerias_
Faustino Nebrera <faustino.nebrera@vass.es>
1.0.0, 13/08/2022
:toc:
:toclevels: 3
:icons: font

== Resumen

Este proyecto representa un ejemplo y template de una cadena CI/CD construida con la idea de simplificar el stack
de productos requeridos, su instalación y, sobre todo, la preparación de pipelines y jobs para los circuitos más
habituales. No se ha pretendido hacer comparativas de productos y, menos aún, establecer una guía estricta de
cómo hacer las cosas. El proyecto es, simplemente, un demostrador del "ahorro" de costes y tiempo de aprendizaje
para establecer cadenas CI/CD no demasiado complejas. 

En esta primera versión la etapa de despliegue se realiza de manera muy simple (mediante SSH), 
y se limita a proyectos maven sobre java/SpringBoot o similares. Partiendo de este template es muy sencillo
agregar las configuraciones correspondientes a otros entornos, tales como node.js, python, Angular, etc.

En versiones posteriores está previsto incluir jobs más complejos para las etapas CD, concretamente para Terraform,
Helm/Kubernetes y Ansible.
 
== Versiones

[cols=".<1,.<1,.<1,.<6", options="header"]
|===
|Vers
|Por
|Fecha
|Notas

|1.0.0
|FNG
|13/08/2022
|Primera versión CI para maven/java

|===

:sectnums:
== Introducción

Los stacks CI/CD más habituales están compuestos de varios productos, especializados cada uno de ellos en un aspecto concreto
de la cadena o pipeline de la solución final. Es muy frecuente encontrar stacks que incluyen 5 o más
productos diferentes: Gitlab, Jenkins, Sonar, Nexus, Vault, Octopus, etc.

Es evidente que instalar (y sobre todo configurar) muchos productos heterogéneos no es un trabajo trivial. Algunos vendors
permiten simplificar esta tarea mediante soluciones previamente integradas (véase el caso de RedHat OpenShift, los servicios
CI/CD de Amazon Web Services, etc.) aunque, lógicamente, no se trata de simples black-boxes, puesto que cada organización
tiene sus propios requisitos de CI/CD. No es lo mismo un pequeño ISV que una gran Entidad Financiera, por lo que siempre es necesario
hacer "retoques" sobre las configuraciones por defecto.

Por otra parte, los coordinadores de circuitos tipo _Jenkins(TM)_ se configuran mediante un lenguaje de
programación que, aunque sencillo, requiere que los ingenieros de DevOps tengan ciertos conocimientos de
programación y estén familiarizados con el lenguaje en cuestión. Si, además (y es lo habitual) el código debe
mantenerse como read-only para los 'developers', y debe ser modular (empleando
librerías), la curva de aprendizaje suele ser costosa.

En este proyecto se ha intentado minimizar:

- El número de productos implicados.
- La complejidad de la definición de
pipelines, todo ello en en base al empleo de las capacidades CI/CD que Gitlab ofrece en sus últimas versiones.

[TIP]
.*Importante*
--
Independientemente de cuál sea su formación previa en CI/CD, la lectura de este documento puede ser útil para afianzar conceptos básicos y entender la filosofía de los pipelines  de CI/CD.
--

== Entorno de desarrollo

=== Hardware y software de base

Server CI/CD::
* Máquina virtual en Hyper-V.
* 24 GB Memoria max.
* 4 procesadores virtuales.
* Ubuntu 20.04.1
* Docker 20.10.17 y docker-compose

Server Despliegue::
* Maquina virtual en Hyper-V.
* 4 GB Memoria max.
* 2 procesadores virtuales.
* Ubuntu 22.04.1
* Docker 20.10.17 y docker-compose.

Workstation::
* Core i7-1165G7
* 16 GB memoria
* 512 GB SSD
* Windows 11 Pro
* Visual Studio Code 1.69.2
* Eclipse 2022-06 (4.24.0)

=== Productos para CI/CD

Todos los productos se han instalado en el server CI/CD como imágenes docker, y se lanzan mediante sendos docker-compose, para facilitar
el arranque/parada de un producto concreto sin afectar al resto. Todos los docker-compose referencian un network
común tipo bridge. Al compartir network, se facilita la comunicación entre containers, puesto que Docker actúa
como DNS interno. Salvo en el caso de Nginx, no se exponen puertos TCP/IP al exterior. El acceso externo se
canaliza a través de Nginx (port 443), que actúa como proxy inverso, discriminando el acceso en base al hostname de destino. Los
productos instalados son:

- Gitlab OMNIBUS 15.2.1-ce.0
- Gitlab-runner: latest
- Sonarqube 9.5.0-community
- PostgreSQL 12.2 (requerido por Sonar)
- Nginx 1.21.6
- Portainer ce:2.14.1

== Visión general de la solución

=== Proyecto de trabajo

Las librerías de pipelines y jobs se encuentran en el proyecto "cicd-librerias", y se describirán con mayor detalle más adelante. Este
proyecto se maneja en la workstation empleando Visual Studio Code.

Como proyecto de trabajo, se ha escogido la aplicación Selfweb de Comunytek, y concretamente el server REST (selfwebspingboot). Se
trata de una aplicación java que emplea el framework SpringBoot. Como gestor de proyectos se emplea maven. En la carpeta "ejemplos_cfg"
puede verse el pom.xml de dicho proyecto, así como otros ejemplos de archivos de configuración. Este proyecto
se maneja en la workstation empleando Eclipse.

El servidor de despliegue pretende simular un entorno real de producción. Se han preinstalado docker y docker-compose. Adicionalmente
están preconstruidos los diferentes volúmenes docker
que emplean Selfweb y Nginx, y preinstalado el cliente javascript de Selfweb (SelfTask).

=== Flujo de desarrollo

Como normativa se ha escogido el modelo "Git Flow" simplificado. Si bien los pipelines pueden fácilmente adaptarse
a otros modelos, este es el preferido por muchas organizaciones, y el que se emplea en este momento en los
proyectos del Clan Comunytek. El modelo es el siguiente:

- Debe existir una rama "master" que además es la de defecto. En esta rama debe estar el código de la última versión
liberada para producción, o en curso de liberarse. La rama está protegida de modo que sólo los "Mantainers"
pueden hacer merge y push.
- Debe existir una rama "develop". En esta rama debe estar el código de la última versión
liberada para preproducción, UAT, Staging, o en curso de liberarse. La rama está protegida de modo que sólo los "Mantainers"
pueden hacer merge y push.
- El desarrollo se realiza sobre ramas auxiliares, asociadas a una "feature", a un desarrollador, etc. Los desarrolladores
trabajan en local sobre su rama y, de forma periódica, hacen "push" a efectos de backup, lo que, opcionalmente,
puede disparar un pipeline de CI/CD. Una vez finalizado el trabajo,
deben hacer pull de "develop", y merge local de la rama de trabajo sobre "develop" para revisar posibles inconsistencias.
- Puede existir una rama hotfix, pero no más de una simultáneamente. Como veremos más tarde, esta rama (de existir) tiene
un tratamiento especial.
- Una vez preparado en local un SNAPSHOT en "develop" incluyendo todas las ramas auxiliares finalizadas, un "Mantainer" hará
push de develop, lo que disparará un pipeline CI/CD.
- Cuando un SNAPSHOT sea autorizado para producción, un "Mantainer" hará merge local de develop sobre master,
modificará la versión en el pom (eliminando la cadena "SNAPSHOT"), y hará push de master, lo que disparará un pipeline CI/CD. 

=== Gitlab como entorno CI/CD

En sus últimas versiones, Gitlab incorpora un conjunto de características que lo hacen un buen
candidato para soportar el grueso de las cadenas CI/CD de manera integrada. A continuación vamos a comentar
algunos de los aspectos principales.

==== Repositorio de código fuente

Git/Gitlab representan el estándar de-facto para la gestión de código fuente. No vamos a entrar
a explicar Git, por ser sobradamente conocido. Sin embargo, hay algunas características menos conocidas
que conviene mencionar.

- Gitlab incluye un *Issue Manager* sencillo pero bastante completo, hasta el punto de que, en algunos casos, podría
emplearse como sustituto de _Jira_(TM).
- También incluye una *Wiki* con soporte de varios lenguajes de markup que, como en el caso anterior,
podría emplearse como sustituto de _Confluence_(TM), al menos en lo que se refiere a documentación de los proyectos.

==== Coordinador CI/CD

Gitlab incluye un coordinador de CI/CD relativamente poco conocido, dado que tradicionalmente sus capacidades han estado por
debajo de los productos más usuales, tales como _Jenkins_(TM) o _TeamCity_(TM). En sus últimas versiones, sin embargo, Gitlab se ha posicionado
como un serio competidor, fundamentalmente por las siguientes razones:

* Todo el "plumbing" de CI/CD está estrechamente integrado con el repositorio de código fuente, emplea la misma interfaz de usuario,
y simplifica la eventual integración de otros productos.

* Los _pipelines_ se definen mediante un lenguaje de markup sobradamente conocido (yaml), lo que evita tener que aprender un lenguaje
específico.

* Si se requieren acciones complejas, el entorno de "shell" está directamente integrado con los jobs. Es muy fácil, además,
crear librerías de funciones escritas en .sh, .bash, etc. y llamarlas directamente desde un job. En un entorno complejo,
los ingenieros DevOps peden concentrarse en la creación de pipelines, dejando los detalles de implementación de cada job a los desarrolladores.

Más adelante se explica en mayor detalle el modo de trabajar con Gitlab CI/CD.

==== Verificación de Calidad del Código

En este apartado, Gitlab no dispone de una solución propia, sino que
integra el producto _CodeClimate(TM)_. Dado que el estándar de facto para esta fase es, desde hace años, _SonarQube(TM)_, el cual además se integra fácilmente con los gestores de proyectos más habituales (maven, gradle, npm..), hemos preferido integrar este producto en el presente ejemplo. Más adelante se explica en detalle este proceso.

==== Tests Unitarios

De nuevo Gitab se apoya en soluciones de terceros tanto para la ejecución de tests unitarios como SAST. En nuestro caso, emplearemos las capacidades embebidas en _maven_, más que suficientes en la mayor parte de los proyectos.

==== Construcción de Artefactos

La mayor parte de los gestores de proyectos (_maven_, _gradle_, _npm_..) disponen de sus propios mecanismos de detección de dependencias y construcción del/los artefactos finales. En este proyecto nos hemos apoyado en las capacidades de _maven_, como se verá más adelante. La adaptación de los jobs a otros entornos es
completamente trivial.

==== Registro de Artefactos

En este aspecto, el mercado está claramente dominado por dos jugadores clave: _Nexus(TM)_ y _Artifactory(TM)_. Gitlab, sin embargo, dispone de un "Package Registry" compatible con los
formatos más habituales, y con funcionalidades básicas, que pensamos 
pueden ser suficientes en muchos casos. Por ello nos hemos basado
en el propio Gitlab en este apartado.

==== Registro de Imágenes Docker

También en este apartado Gitlab dispone de un "Component Registry" muy flexible, por lo que es el que se ha empleado en este
ejemplo.

==== Despliegue

En esta primera versión, el despliegue de la imagen Docker generada se realiza de una manera muy simple (utilizando SSH).
Gitlab dispone de integraciones directas con Terraform, Helmet/Kubernetes, Ansible, etc. por lo que en posteriores versiones
de este proyecto se trabajará con estas posibilidades. 

=== Un vistazo a Gitlab CI/CD

Obviamente, no es objeto de este documento explicar pormenorizadamente el trabajo con Gitlab CI/CD, pero sí
que es interesante comentar los aspectos principales.

- Lo primero que llama la atención de Gitlab CI/CD es que existe un *único* archivo de definición
de pipelines por proyecto. Este archivo debe localizarse en la raíz del proyecto, y debe denominarse obligatoriamente ".gitlab-ci.yml". El
formato del archivo es yaml, con unas keywords bastante sencillas de aprender.
- No obstante lo anterior, este .yml puede contener "includes" de otro/s archivo/s .yml, los cuales a su vez pueden tener includes, y así sucesivamente.
Además, los includes pueden referenciar otro proyecto, por lo que es sencillo montar un proyecto específico para almacenar estos includes,
como es el caso de este ejemplo.
- El pipeline se compone de etapas (stages), y de definiciones de trabajos (jobs) asociados a las diferentes etapas. Puede haber más de un job asociado a un stage, bien sea para que se ejecuten en paralelo o úno sólo de ellos en función de los valores de ciertas variables.
- En cada job se definen reglas (rules) para incluir o no este job en el pipeline, y en qué condiciones de ejecución. Por ejemplo, un job "manual" quedará bloqueado en el pipeline hasta que sea lanzado por un Mantainer.
- Cuando se dispara un evento CI/CD, Gitlab analiza todas las reglas y monta de manera dinámica un pipeline que contiene sólamente los jobs en los que se cumplen las reglas. Esto nos permite tener "n" pipelines distintos, cada uno asociado a un conjunto de reglas. Como puede verse, se trata de una modalidad de trabajo muy diferente a la de Jenkins o Artifactory.
- También mediante reglas, podemos definir si permitimos o no que el job falle y, en consecuencia, que el pipeline continue. Por ejemplo, en un job que ejecute Sonar, permitimos que falle en la rama "develop", al no tratarse de un release a producción.
- Podemos incluir en el job un "before_script" y un "after_script", además del "script" principal. Por ejemplo, podemos definir un after_script que se debe ejecutar sólo si el job falla, para hacer rollout o preparar una fase posterior.
- En gitlab debemos tener uno o más "runners" que se encargan de gestionar la ejecución de los jobs, lanzando un "executor" específico para ese job. En este ejemplo, hemos configurado un runner tipo Docker, que se ejecuta como un container separado de Gitlab. Este runner, para cada job que se le asigna,
crea a su vez un container Docker con la imagen que se indique en el propio job, y es en este container donde se ejecutan los scripts, que se escriben en el lenguaje de shell asociado a la imagen docker, es decir, "sh", "bash", "PowerShell", etc.
- Para este ejemplo hemos preparado una imagen de executor denominada "ck-maven-executor", basada en un linux lightweight (Alpine) sobre el que se preinstalan maven, git y otros módulos de utilidad. De este modo, nos "ahorramos" todo el tiempo que requiere la instalación de estos componentes cada vez que ejecutemos un job.
- Gitlab dispone de varios mecanismos para "pasar" información de un job a otro. Posiblemente el más usado es el "cache", en el que podemos incluir uno o más directorios de trabajo que cada job "lee" al inciarse y "escribe" al finalizar. Un ejemplo típico de uso es el repositorio de dependencias de maven. Si está en cache, se descargarán sólamente una vez y estarán a disposicion de los diferentes jobs.
- Un elemento clave en la definición del pipeline son las "variables". En Gitlab, existen varios niveles de variables:
* Variables predefinidas de Gitlab: Todas ellas comienzan con "CI_" y pueden contener tanto información estática como dinámica. Por ejemplo, CI_PROJECT_ID
contiene el ID del proyecto (estática), mientras que CI_COMMIT_REF_NAME contiene el nombre del branch sobre el que está trabajando el pipeline (dinámica).
* Variables de Grupo: Se definen en la configuración del grupo de proyectos. Pueden estar enmascaradas, para que no sean visibles en logs (p.e. passwords). Al estar asociadas al grupo, sólo los usuarios de nivel "Mantainer" en el grupo tienen derecho a visualizarlas y modificarlas. Aunque se trata de un mecaniso bastante simple, nos permite "ahorrarnos" un gestor de secretos (p.e. Vault) en las fases de CI/CD.
* Variables de Proyecto: Similares a las anteriores, sólo que específicas del proyecto
* Variables de Pipeline: Están asociadas al pipeline del proyecto y son modificables tanto por Mantainers como por Developers. Pueden definirse en alguno de los includes, o bien en el .yml principal.
* Variables de Job: Son específicas de cada job, y tienen vigencia sólo durante la ejecución de dicho job.
* Variables de Entorno: Específicas de cada script. Normalmente son variables de trabajo, aunque es posible pasarlas a jobs subsiguientes mediante el mecanismo de paso de artefactos "dotenv" que comentaremos más adelante.

- El pipeline se dispara al ocurrir determinados eventos (commit, push, merge_request). Tanto a nivel pipeline como individualmente por job podemos "filtrar" los eventos que nos interese. En este ejemplo, en las reglas a nivel pipeline hemos definido que sólo nos interesan los eventos "push".
- Gitlab dispone de muchos otros mecanismos (pipelines multiproyecto, triggres externos, webhooks, etc.) que no han sido necesarios en este ejemplo, por lo que no entramos en su descripción. 

== Descripción de las librerías

En esta primera versión del proyecto, empleamos únicamente dos productos: Gitlab y SonarQube. Esto contrasta con los 4, 5 o 6 productos que se emplean habitulamnete en cadenas CI/CD. Estos dos productos, además, resultan muy familiares tanto a ingenieros DevOps como a desarrolladores.

En el proyecto se demuestra, además, que Gitlab CI/CD puede sustituir perfectamente a Jenkins o TeamCity, y con un lenguaje de definición de pipelines muy simple y de rápida curva de aprendizaje.

=== Layout

Se ha creado un proyecto Git denominado "cicd-librerias" dentro del grupo de proyectos "comunytek". En este grupo de proyectos se encuentra también el proyecto "selfwebspringboot" que usaremos como ejemplo de la implementación de las librerías.

- En _cicd-librerias_ se han creado 3 carpetas:

* ejemplos_cfg: Incluye ejemplos de configuraciones en los proyectos base, tales como ".gitlab-ci.yml", "pom.xml", etc.
* pipelines: Contiene los includes principales para los diferentes entornos. En esta versión sólo está definido el relativo a maven/java.
* jobs: Contiene una carpeta para cada entorno (en este ejemplo, solamente maven), y en cada carpeta, los includes de cada job del pipeline.

- En _selfwebspringboot_ se ha creado el archivo ".gitlab-ci.yml", como ejemplo de integración de las librerías _cicd-librerias_.

=== Variables

==== De Grupo

A nivel del grupo de proyectos (en este caso "comunytek") es necesario definir las siguientes variables:

CICD_USER:: Usuario de gitlab con suficientes derechos para llamar a la API de Gitlab en relación al proyecto. Normalmente será un Mantainer.
CICD_PASSWD:: Password del usuario anterior.
CICD_TOKEN:: Personal token creado para el usuario anterior (en settings de usuario).
CICD_EMAIL:: Dirección de correo del usuario anterior.
CICD_HOST:: Nombre del host donde se encuentra instalado Gitlab (p.e. "git2.comunytek.com").
CICD_REGISTRY_HOST:: Nombre del host para el acceso al registry Docker. Aunque se trata del propio Gitlab, atiende a un puerto distinto, por lo que hemos de discriminarlo por el nombre del host (p.e. "https://registry2.comunytek.com").
CICD_SSH_KEY:: Variable tipo "file" que contiene la clave SSH privada para el acceso al host de despliegue.
CICD_DEPLOY_USER:: Usuario con el que se realizará la conexión SSH con el servidor de despliegue.
CICD_DEPLOY_HOST:: Nombre o IP del servidor de despliegue.
CICD_DEPLOY_HOST_SNAPSHOT:: Nombre o IP del servidor de despliegue para UAT, QA, o staging (versiones SNAPSHOT).
SONAR_HOST_URL:: Url completa del host donde está instalado Sonarqube (p.e. "https://sonar2.comunytek.com").
SONAR_HOST_TOKEN:: Token generado en Sonar para acceso externo mediante la API.

==== De pipeline (ocultas)

En el include principal del pipeline se definen un conjunto de variables que quedan ocultas para los Developers, y que se han utilizado como base para implementar los diferentes flujos. Un Manager de Grupo puede modificar el comportamiento del pipeline sin más que actualizar estas variables. También es posible (si se desea) definir alguna de estas variables en el archivo ".gitlab-ci.yml" del proyecto, el cual, a priori, es editable por los Developers.

IGNORE_AUX_BRANCHES:: No ejecutar el pipeline en ramas auxiliares (aquellas distintas de 'master' y 'develop').
Si se define a "true", el resto de flags relacionados con ramas auxiliares no tienen efecto.
Como excepcion, la rama identificada como HOTFIX_BRANCH (si existe) siempre pasa.
COMPILE_AUX_BRANCHES:: Compilar o no ante un push en ramas auxiliares.
SONAR_AUX_BRANCHES:: Pasar o no Sonar en ramas auxiliares. En cualquier caso se admite que falle.
TEST_AUX_BRANCHES:: Pasar o no test unitarios en ramas auxiliares. En cualquier caso se admite que falle.
ALLOW_FAILURE_IN_SONAR_DEVELOP:: Permitir fallo al pasar Sonar en rama develop.
ALLOW_FAILURE_IN_TEST_DEVELOP:: Permitir fallo al pasar tests unitarios en rama develop.
ALLOW_RELEASE_IN_DEVELOP:: Permitir versiones release (no son SNAPSHOT) en rama develop. Normalmente será "false", pero puede haber circunstancias específicas en que sea necesario permitirlo. Nótese que nunca permitimos versiones SNAPSHOT en rama master.
REGISTER_DEVELOP:: Registrar, generar imagen docker y tag de la rama 'develop'. Debe indicarse a "true"
si la rama 'develop' representa despliegues oficiales en preproducción, UAT, QA o staging.
Si se establece como "false", el pipeline termina con la generación del fat-jar y su
almacenamiento temporal como artefacto.

==== De pipeline (editables)

Se trata de variables definidas en el ".gitlab-ci.yml" del proyecto y que son, por tanto, editables por los Developers, para tratar circunstancias específicas.

SNAPSHOT_NUMBER:: Si registramos, creamos docker y tag, etc. en SNAPSHOT podemos agregar (opcionalmente)
un numero de snapshot a la vesion del proyecto para identificar registros y tag. Nótese que, si la versión en el pom junto con este indentificador ya está registrada, el job de registro terminará con error, y el pipeline se interrumpirá.
HOTFIX_BRANCH:: Indicar la rama de hotfix en la que estamos trabajando, si es que existe. En esta rama, se ejecuta todo el pipeline,
aunque las etapas sonar y test admiten errores.
Comentar esta linea, o dejar en blanco el valor, una vez liberado el hotfix.
HOTFIX_NUMBER:: Opcionalmente, podemos indicar un numero de hotfix, para registro, docker y tag.
En la version del proyecto, se respeta la que se indica en el pom.xml. 

=== Pipeline del proyecto e include principal

En el proyecto _selfwebspringboot_ se ha creado el archivo ".gitlab-ci.yml" con el contenido siguiente:

------------------------------------------------------------
variables:
  SNAPSHOT_NUMBER: "005"
  HOTFIX_BRANCH: ""
  HOTFIX_NUMBER: "002"
include:
   project: 'comunytek/cicd-librerias'
   ref: master
   file: 'pipelines/maven-springboot-simple.yml'
------------------------------------------------------------

Como puede verse, simplemente se definen las variables de pipeline editables, y se incluye el resto de la definición del pipeline tomada del proyecto _cicd-librerias_.

El include principal sólo es editable por Managers de Grupo. En este ejemplo, mostramos a continuación un extracto de su contenido.

------------------------------------------------------------
variables:
  ##
  # Variables Básicas del pipeline
  ##
  SONAR_USER_HOME: "${CI_PROJECT_DIR}/.sonar"    # Home de sonar, para caching
  GIT_DEPTH: "0"  # No usar shallow clone (es un proyecto pequeño)
  MAVEN_OPTS: "-Dmaven.repo.local=./.m2/repository"    # Localizacion del repositorio maven
  ORIGIN_URL: "https://oauth2:${CICD_TOKEN}@${CICD_HOST}/${CI_PROJECT_PATH}.git"  # Url externa de gitlab
  ##
  # Variables de pipeline ocultas.
  # Si se desea, y para mayor seguridad, pueden definirse como variables CI/CD de grupo.
  #
  IGNORE_AUX_BRANCHES: "false"
  COMPILE_AUX_BRANCHES: "true"
  ... resto de variables

workflow:
  rules:
    - if: $CI_COMMIT_TAG        # No ejecutar en tags                   
      when: never
    # No ejecutar este pipeline en ramas auxiliares, si así esta configurado
    - if: $IGNORE_AUX_BRANCHES == "true" && $CI_COMMIT_REF_NAME != "develop" && $CI_COMMIT_REF_NAME != "master" && $CI_COMMIT_REF_NAME != $HOTFIX_BRANCH
      when: never
    - if: $CI_PIPELINE_SOURCE == 'push'    # Ejecutar sólo en push 

image: ck-maven-executor:1.0.0     # Imagen por defecto

cache:
  # Definimos la clave del cache como el nombre del branch en el que hacemos push, de este modo
  # separamos la informacion cacheada para cada rama, para no interferir en otros pipelines.
  key: "$CI_COMMIT_REF_NAME"

# Etapas posibles del pipeline
stages:
  - prepare
  - compile
  - sonar
  - test
  - build
  - register
  - docker
  - tag
  - deploy

# Includes, uno por job
include: 
  - project: 'comunytek/cicd-librerias'
    ref: master
    file: 
      - 'jobs/maven/prepare-simple.yml'
      - 'jobs/maven/compile-simple.yml'
      ... resto de includes
------------------------------------------------------------

=== Jobs específicos para maven

Consulte el código _yaml_ de cada job para ver el detalle de su funcionalidad. A continuación indicamos algunos comentarios aclaratorios.

==== Prepare

Para esta etapa se ha definido el job en el archivo link:jobs/maven/prepare-simple.yml[]. Este job se ejecuta incondicionalmente en todas las
ramas al hacer push, excepto en ramas auxiliares si el flag IGNORE_AUX_BRANCHES está a true (todo el pipeline simplemente se ignora). El job prepara el entorno para la ejecución de jobs posteriores.

- Define los directorios que forman parte del cache.
- Calcula una serie de variables de entorno, útiles para todo el pipeline.
- Si existe el directorio "target", ejecuta "mvn clean".
- Copia las claves y valores de las variables de entorno a un archivo temporal "prepare.env".
- Pasa el contenido de "prepare.env" al resto del pipeline mediante un artefacto de tipo "reports" y clave "dotenv". Las variables contenidas en este archivo son accesibles en todo el pipeline.

==== Compile

El job en se define en link:jobs/maven/compile-simple.yml[]. Se ejecuta incondicionalmente en todas las ramas al hacer push, excepto en ramas auxiliares si el flag COMPILE_AUX_BRANCHES está a false (o bien el flag IGNORE_AUX_BRANCHES está a false, lo que aplica a todo el pipeline). También se ejecuta en la rama hotfix (si existe). En este ejemplo, el job es bastante simple:

- Define los directorios de la cache.
- Ejecuta "mvn compile". Si se produce un error de compilación, el pipeline se detiene.

==== Sonar

Para esta etapa se ha definido el job en el archivo link:jobs/maven/sonar-simple.yml[]. Se ejecuta incondicionalmente en todas las ramas al hacer push, excepto en ramas auxiliares si el flag SONAR_AUX_BRANCHES está a false. También se ejecuta en la rama hotfix (si existe). Se ejecuta Sonarqube sobre el código fuente para localizar bugs, code-smells y vulnerabilidades SAST.

- Se permite continuar en caso de error en hotfix y ramas auxiliares, así como en develop siempre que el flag ALLOW_FAILURE_IN_SONAR_DEVELOP se defina como true.
- En ramas auxiliares se pasa Sonar sólo en archivos modificados, mientras que en el resto de ramas se pasa a todo el código. 
- Se ejecuta "mvn validate sonar:sonar".

==== Test

Job definido en link:jobs/maven/test-simple.yml[]. Se ejecuta incondicionalmente en todas las ramas al hacer push, excepto en ramas auxiliares si el flag TEST_AUX_BRANCHES está a false. Nótese que en la rama hotfix (si existe) también se ejecuta este job. El objetivo del job es pasar los test unitarios definidos para el proyecto.

- Se permite continuar en caso de error en hotfix y ramas auxiliares, así como en develop siempre que el flag ALLOW_FAILURE_IN_TEST_DEVELOP se defina como true.
- Se ejecuta "mvn test".

==== Build

Para esta etapa se ha definido el job en el archivo link:jobs/maven/build-simple.yml[]. Este job se ejecuta incondicionalmente en master, develop y hotfix al hacer push. No se ejecuta en ramas auxiliares. Se trata de construir el artefacto objeto del proyecto. En el caso de maven/SpringBoot se trataría del llamado "fat-jar".

- Se ejecuta "mvn package". Si da error, se detiene el pipeline.
- Si estamos en la rama master y la versión del proyecto es SNAPSHOT, salimos con error 2 (no se permite SNAPSHOT en master).
- Si estamos en la rama develop, la versión del proyecto NO es SNAPSHOT y el flag "ALLOW_RELEASE_IN_DEVELOP" es false, salimos con error 3 (no se permite release en develop).
- Si estamos en develop y el flag REGISTER_DEVELOP es false, salimos con error 4 (la rama develop no se registra), con lo que detenemos el pipeline.
- Si salimos con error, generamos un artefacto compuesto por el fat-jar, el pom y el .gitlab-ci.yml. Este artefacto está disponible para su descarga durante un periodo de 2 horas. La idea es que, si se genera alguno de los errores anteriores, el pipeline se detenga, pero dispongamos del artefacto para pruebas adicionales, condiciones no contempladas, etc.

==== Register

Job definido en link:jobs/maven/register-simple.yml[]. Se ejecuta en master, hotfix y develop (si el flag REGISTER_DEVELOP es true) al hacer push. No se ejecuta en ramas auxiliares. Este job asume que se ha ejecutado la etapa "build" y diponemos, por tanto, del "fat-jar" en la cache. Para que el job ejecute con éxito, se precisan unos requisitos previos:

- Habilitar (si no lo está) el "Package Registry" de Gitlab y configurarlo para que no acepte duplicados.
- Configurar, en el pom.xml, los registries para snapshot y release (dentro del elemento <distributionManagement>).
- Crear un archivo "ci_settings.xml" definiendo las credenciales de acceso a el/los registries.
- En el directorio "ejemplos_cfg/maven" pueden verse ejemplos para un proyecto real.

El job prepara un artifact ID del siguiente modo:

- En rama master, el ID es la versión del proyecto en el pom (debe ser de release). Como es lógico, no puede registrarse la misma versión más de una vez.
- En rama develop, y si es SNAPSHOT, se agrega a la versión del proyecto el valor de la variable SNAPSHOT_NUMBER, con lo quedaría algo como "5.0.6-SNAPSHOT.003". De este modo, podemos liberar para UAT o staging más de una versión intermedia, en forma de "release candidate", pero manteniendo registrada toda la historia de este SNAPSHOT.
- En rama develop, si NO es SNAPSHOT, y aceptamos release en develop (variable ALLOW_RELEASE_IN_DEVELOP a true), agregamos a la versión del proyecto la cadena "-DEVELOP" seguida del SNAPSHOT_NUMBER, es decir, algo como "5.0.6-DEVELOP.003". Es una situación bastante rara, puesto que se sale de la normativa básica de flujo, pero hemos dejado abierta esta posibilidad para acomodar circunstancias excepcionales.
- En rama hotfix (si existe), agregamos a la versión del proyecto la cadena "-HOTFIX" seguida del HOTFIX_NUMBER, es decir, algo como "5.0.6-HOTFIX.002".

Finalmente, creamos un tar con los fuentes y registramos un artefacto compuesto por el fat-jar, el pom y el tar:

----------------------------------------------------
      SRC_FILE="./{PRJ_VERS}-src.tgz"
      tar czf ${SRC_FILE} ./src/*
      mvn validate deploy:deploy-file -s ci_settings.xml \
      -Durl="${REG_URL}" \
      -DrepositoryId="gitlab-maven" \
      -Dfile="${JAR_FILE}" \
      -DpomFile="pom.xml" \
      ${VERSION} \
      -Dfiles=${SRC_FILE} \
      -Dclassifiers=src \
      -Dtypes=tgz
----------------------------------------------------

==== Docker

Para esta etapa se ha definido el job en el archivo link:jobs/maven/docker-simple.yml[]. Este job se ejecuta incondicionalmente en master y hotfix al hacer push. No se ejecuta en ramas auxiliares. Adicionalmente puede ejecutarse en develop si REGISTER_DEVELOP es true.Sólo se ejecuta si existe, en la raiz del proyecto, un archivo "Dockerfile".

El job prepara un Image ID del siguiente modo:

- En rama master, agregamos al Id base la cadena "/release". Nótese que el Component Registry SI admite duplicados.
- En rama develop, y si es SNAPSHOT, se agrega al Id base la cadena "/snapshot", y a la versión de proyecto el SNAPSHOT_NUMBER.
- En rama develop, si NO es SNAPSHOT, y aceptamos release en develop (variable ALLOW_RELEASE_IN_DEVELOP a true), agregamos al Id base cadena "/develop-release", y a la versión de proyecto el SNAPSHOT_NUMBER.
- En rama hotfix (si existe), agregamos al Id de base la cadena "/hotfix", y a la versión de proyecto el HOTFIX_NUMBER.

El job guarda el IMG_TAG generado en el archivo "prepare.env", y lo pasa como artefacto a etapas posteriores. Además:

- Crea la imagen Docker en base al Dockerfile.
- Hace login al Component Container de nuestro Gitlab.
- Registra la imagen mediante "docker push".

-------------------------------------------------
    - 'echo "IMG_TAG=${IMG_TAG}" >> prepare.env'
    - docker -v
    - 'echo "$CICD_PASSWD" | docker login -u $CICD_USER --password-stdin $CICD_REGISTRY_HOST'
    - docker build -t $IMG_TAG .
    - docker push $IMG_TAG 
-------------------------------------------------

==== Tag

Job definido en link:jobs/maven/tag-simple.yml[]. Se ejecuta en master, hotfix y develop (si el flag REGISTER_DEVELOP es true) al hacer push. El job se ha definido como "manual". Esto significa que queda bloqueado dentro de la cadena del pipeline hasta que se libere manualmente. En gitlab, no existe, por el momento, un mecanismo directo de interacción con la consola pero podemos, de forma indirecta, controlar el flujo. Por ejemplo, en este caso, se ha definido una variable de job llamada SEGUIR, con valor inicial false. Si en el job pulsamos el icono de "play", la variable no cambiará su valor. Por contra, si pulsamos sobre el nombre del job, se nos presenta un formulario en el que podemos agregar o modificar el valor de variables locales. En este ejemplo, podemos definir la variable SEGUIR a true, con lo que podemos, en el script, continuar la ejecución o pasar a la siguiente etapa:

-------------------------------------------------
  variables:
    SEGUIR: "false"
  script:
    - '[[ $SEGUIR != "true" ]] && { echo "WARN: Para ejecutar este job debe establecer la variable SEGUIR a true"; exit 0; }'
-------------------------------------------------

A continuación el job computa un TagID, de acuerdo los siguientes criterios:

- Si estamos en la rama master, el TagID se forma con la cadena "release-" seguida de la versión del proyecto, es decir, algo como "release-5.0.6".
- En rama develop, y si es SNAPSHOT, se forma con la cadena "snapshot-", la versión de proyecto y el SNAPSHOT_NUMBER. Algo como "snapshot-5.0.6-SNAPSHOT.003".
- En rama develop, si NO es SNAPSHOT, y aceptamos release en develop (variable ALLOW_RELEASE_IN_DEVELOP a true), se forma con cadena "develop-release-", la versión de proyecto y el SNAPSHOT_NUMBER. Algo como "develop-release-5.0.6.003".
- En rama hotfix (si existe), se forma con la cadena "hotfix-", la versión de proyecto y el HOTFIX_NUMBER. Algo como "hotfix-5.0.6.002".

Con este Id se genera un tag. Nótese que los TagID no pueden repetirse. 

-------------------------------------------------
    - git config user.name "$CICD_USER"
    - git config user.email "$CICD_EMAIL"
    - git remote remove origin
    - git remote add origin ${ORIGIN_URL}
    - git tag -a $TAG -m "Build $TAG"
    - git push origin $TAG
-------------------------------------------------

==== Deploy

Para esta etapa se ha definido el job en el archivo link:jobs/maven/deploy-simple.yml[].
En esta primera versión este job se ha planteado de una forma muy simple, aunque en próximas versiones se incorporarán aspectos de IaC y despliegues más sofisticados. En este ejemplo, se parte de la siguiente situación:

- Debemos desplegar la imagen Docker generada en etapas anteriores en un host remoto, al que tenemos acceso sólo mediante SSH empleando clave privada. El host remoto será el de producción (rama master) o bien el de UAT o staging (rama develop, siempre que REGISTER_DEVELOP sea true). No se hace deploy ni en hotfix ni en ramas auxiliares.
- En el host remoto están preinstalados docker y docker-compose, así como los volúmenes y network empleados por nginx y selfwebspringboot.
- La configuración de docker está basada en dos archivos que emplean la designación por defecto de docker-compose, es decir "docker-compose.yml" y "docker-compose.override.yml". Este último archivo será reescrito por el job, con un contenido similar a este:

-------------------------------------------------
services:
    selfweb:
        image: registry2.comunytek.com/comunytek/selfweb/selfwebspringboot/snapshot:5.0.6-SNAPSHOT.003
-------------------------------------------------

Donde la entrada "image:" es el TagId creado anteriormente en la etapa "docker", que incluye el host del registry.

Este job es también manual, y emplea el mismo mecanismo para seguir o no que el utilizado en la etapa "tag".

La parte interesante del script es ésta:
-------------------------------------------------
      CONN_STRING="${CICD_SSH_DEPLOY_USER}@${CICD_SSH_DEPLOY_HOST}"
      [[ $IS_SNAPSHOT == "true" ]] && CONN_STRING="${CICD_SSH_DEPLOY_USER}@${CICD_SSH_DEPLOY_HOST_SNAPSHOT}"
      ssh -o StrictHostKeyChecking=no -i ${CICD_SSH_KEY} ${CONN_STRING} "
      cd selfweb &&
      docker-compose down &&
      echo 'services:' > docker-compose.override.yml &&
      echo '    selfweb:' >> docker-compose.override.yml &&
      echo '        image: ${IMG_TAG}' >> docker-compose.override.yml &&
      docker-compose up -d &&
      docker ps
      "
-------------------------------------------------

== Casos de uso

Para los casos de uso que siguen, se parte de la siguiente configuración de variables:

* IGNORE_AUX_BRANCHES: false
* COMPILE_AUX_BRANCHES: true
* SONAR_AUX_BRANCHES: true
* TEST_AUX_BRANCHES: false
* ALLOW_FAILURE_IN_SONAR_DEVELOP: false
* ALLOW_FAILURE_IN_TEST_DEVELOP: false
* ALLOW_RELEASE_IN_DEVELOP: false
* REGISTER_DEVELOP: true
* SNAPSHOT_NUMBER: "003"
* HOTFIX_BRANCH: "Hotfix-Issue-23056"
* HOTFIX_NUMBER: "002"

=== Ramas auxiliares

Habitualmente un único desarrollador trabajará en la rama "X", en su PC personal, y con un repositorio git local clonado inicialmente desde el servidor Gitlab.

- Periódicamente, hará commit  de los cambios realizados a su repositorio local.
- Sea por razones de backup, por haber finalizado un sprint, etc., hará push de la rama auxiliar, lo que disparará el pipeline.
- Dado que IGNORE_AUX_BRANCHES es false, el pipeline se ejecuta, con los stages:
* prepare: Comportamiento normal.
* complile: Se ejecuta, al ser COMPILE_AUX_BRANCHES = true.
* sonar: Se ejecuta, al ser SONAR_AUX_BRANCHES = true. Se pasa sonar sólo a los archivos modificados y se permite errores.
* NO se ejecuta la etapa test, al ser TEST_AUX_BRANCHES = false.

Como puede verse, se trata símplemente de verificar que el código fuente actual compila sin errores y pasa o no sonar.

=== Rama develop

El tratamiento de esta rama es bastante más complejo, puesto que en su desarrollo pueden intervenir varias personas. Además, si el flag REGISTER_DEVELOP es true, vamos a hacer un despliegue "oficial" a UAT o staging, por lo que hemos de ser cuidadosos.

- A medida que los desarrolladores van finalizando su trabajo en su rama "X, Y,..", hacen lo siguiente:
* Hacen pull de la rama develop, para obtener el último código disponible.
* Hacen merge (en local) de su rama "X" sobre develop. Si hay conflictos, deben resolverse en la rama "X" y repetir el proceso.
* Notifican al Project Leader que su trabajo está concluido, al menos provisionalmente.

- El Project Leader, una vez finalizadas todas las ramas que conforman el SNAPSHOT, hace lo siguiente:
* Hace pull de develop a su repositorio local.
* Para cada una de las ramas auxiliares que conforman el SNAPSHOT hace merge en local de la rama auxiliar sobre develop. Si todavía quedan conflictos, deben resolverse entre los desarrolladores, y repetir el circuito.
* Una vez resueltos los conflictos, actualiza el pom de develop con la versión fijada para el SNAPSHOT. Si admitimos snapshots incrementales, se define el número de snapshot en la variable SNAPSHOT_NUMBER.
* Hace push de la rama develop, lo que dispara el pipeline.

- Con esta configuración, el pipeline funcionará del siguiente modo:

* prepare: Comportamiento normal.
* compile: Comportamiento normal.
* sonar: Se pasa para todo el código, y NO se admiten errores (ALLOW_FAILURE_IN_SONAR_DEVELOP = false).
* test: Se pasan tests unitarios, y NO se admiten errores (ALLOW_FAILURE_IN_TEST_DEVELOP = false).
* build: Se crea el "fat-jar" y, posteriormente, se verifican condiciones para continuar el pipeline. Si no se cumplen, se genera un artefacto con el .jar y el pom, el cual queda disponible para download por un corto periodo de tiempo (en el ejemplo 2 horas). Una de las condiciones para continuar es que REGISTER_DEVELOP valga true. Si, a pesar de estar en la rama develop, la versión del proyecto NO es SNAPSHOT, y dado que ALLOW_RELEASE_IN_SNAPSHOT es false, el pipeline se interrumpirá.
* register: Se intenta registrar un artefacto compuesto por el fat-jar, el pom y un tgz conteniendo los fuentes actuales en el "Package Registry" de gitlab. El Id del artefacto no puede repetirse, y así el artefacto se convierte en el "single source of truth" de las diferentes versiones registradas. En este ejemplo, al tratarse de un registro tipo maven, podría (si se tratase de una líbrería) emplearse como dependencia en otros proyectos.
* docker: Sólo si se trata de un proyecto docker. Se genera la imagen docker y se registra en el "Container Registry" de gitlab.
* tag: Se ejecuta de forma manual y sólo opcionalmente (ver definición del job). Se crea un nuevo Tag con Id único que incluye el SNAPSHOT_NUMBER.
* deploy: Sólo si se trata de un proyecto docker. Se ejecuta de forma manual y sólo opcionalmente (ver definición del job). Se despliega la imegen docker generada en la etapa "docker" anterior en el host definido por CICD_SSH_DEPLOY_HOST_SNAPSHOT, usando SSH sobre un entorno preconfigurado.

=== Rama master

En el modelo de flujo que hemos seleccionado, la rama master contiene únicamente la última versión para producción (release). Es por ello que el trabajo sobre esta rama es muy delicado, estando su manejo reservado a usuarios de nivel Mantainer y, preferentemente, al Project Leader.

- Una vez que último SNAPSHOT ha sido aprobado, el Project Leader hace lo siguiente:
* Hace pull de develop a su repositorio local, y se asegura de que se trata de la versión SNAPSHOT aprobada para producción.
* Para evitar errores, hace pull de master, y comprueba que se trata de la última versión de release.
* Hace merge de develop sobre master, y resuelve los eventuales conflictos con la ayuda del resto del equipo.
* Modifica la versión del proyecto en master para eliminar la cadena "-SNAPSHOT".
* Hace push de master, lo que dispara el pipeline.

- Con esta configuración, el pipeline funcionará del siguiente modo:

* prepare: Comportamiento normal.
* compile: Comportamiento normal.
* sonar: Se pasa para todo el código, y NO se admiten errores.
* test: Se pasan tests unitarios, y NO se admiten errores.
* build: Se crea el "fat-jar" y, se verifica que la versión del proyecto NO es SNAPSHOT. Si no se cumple, se genera un artefacto con el .jar y el pom, el cual queda disponible para download por un corto periodo de tiempo (en el ejemplo 2 horas) y se interrumpe el pipeline.
* register: Se intenta registrar un artefacto compuesto por el fat-jar, el pom y un tgz conteniendo los fuentes actuales en el "Package Registry" de gitlab. El Id del artefacto no puede repetirse, y así el artefacto se convierte en el "single source of truth" de las diferentes versiones registradas. En este ejemplo, al tratarse de un registro tipo maven, podría (si se tratase de una líbrería) emplearse como dependencia en otros proyectos.
* docker: Sólo si se trata de un proyecto docker. Se genera la imagen docker y se registra en el "Container Registry" de gitlab.
* tag: Se ejecuta de forma manual y sólo opcionalmente (ver definición del job). Se crea un nuevo Tag con Id único (la versión del proyecto).
* deploy: Sólo si se trata de un proyecto docker. Se ejecuta de forma manual y sólo opcionalmente (ver definición del job). Se despliega la imegen docker generada en la etapa "docker" anterior en el host definido por CICD_SSH_DEPLOY_HOST, usando SSH sobre un entorno preconfigurado.

=== Rama hotfix

En este ejemplo se ha dejado bastante libertad al tratamiento de eventuales ramas hotfix, puesto que cada organización tiene su ropia normativa, que deberá implementarse en la definición final del pipeline.

- Si es preciso crear y liberar un hotfix, se procederá del siguiente modo:
* El project leader creará, a partir del tag de la versión de release implicada, una nueva rama, designada de acuerdo con la normativa de la organización (p.e. un Issue #). Para que la nueva rama sea considerada hotfix, se modificará la variable HOTFIX_BRANCH para que contenga el nombre de dicha rama. El HOTFIX_NUMBER se definirá con un valor inicial, p.e. "001". Si posteriormente es preciso repetir el registro, este número se deberá ir incrementando.
* El desarrollo del parche se realizará bien en la propia rama de hotfix (si e trata de un trabajo de menor cuantía), o bien en una o más ramas auxiliares con las que después de hará merge sobre la de hotfix.
* Una vez finalizado el hotfix, se hará push de su rama, lo que disparará el pipeline.
* Nótese que, dependiendo de la normativa de la organización, los cambios realizados o bien se repetirán sobre el trabajo en curso en SNAPSHOT, o bien se incluirá la rama hotfix en una de las que se hará merge sobre develop antes de liberar el SNAPSHOT.
* Una vez finalizado el pipeline con éxito, lo normal es que se elimine la rama de hotfix.

- Con esta configuración, el pipeline funcionará del siguiente modo:

* prepare: Comportamiento normal.
* compile: Comportamiento normal.
* sonar: Se pasa para todo el código, y SI se admiten errores.
* test: Se pasan tests unitarios, y SI se admiten errores.
* build: Se crea el "fat-jar" y no se hacen más comprobaciones.
* register: Se intenta registrar un artefacto compuesto por el fat-jar, el pom y un tgz conteniendo los fuentes actuales en el "Package Registry" de gitlab. El Id del artefacto no puede repetirse, por lo que a la versión del proyecto se agrega el HOTFIX_NUMBER, y el artefacto se convierte en el "single source of truth" de las diferentes versiones hotfix registradas. En este ejemplo, al tratarse de un registro tipo maven, podría (si se tratase de una líbrería) emplearse como dependencia en otros proyectos.
* docker: Sólo si se trata de un proyecto docker. Se genera la imagen docker y se registra en el "Container Registry" de gitlab.
* tag: NO se ejecuta.
* deploy: NO se ejecuta.

== Conclusión

En el presente proyecto se ha comprobado que es posible obtener un ahorro importante, tanto en horas/hombre como en curva de aprendizaje, empleando Gitlab CI/CD como herramnienta básica del proceso, frente a otras soluciones multi-producto, aunque, lógicamente, no se llegue al nivel de sofisticación y complejidad que pueden aportar las mismas. Adicionalmente, la definición de pipelines realizada, si bien es sólo un ejemplo, puede emplearse como "template" y adaptarse a los requisitos de muchas organizaciones.
